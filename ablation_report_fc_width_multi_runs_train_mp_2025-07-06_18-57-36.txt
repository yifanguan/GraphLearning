/Users/yifanguan/gnn_research/GraphLearning/venv/bin/python main.py --fc_width --train_mp --num_runs 3
num_runs 3
Begin abalation study
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 0
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 16
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.8149, Train: 30.00%, Valid: 15.40%, Test: 20.00%, Best Valid: 31.60%, Best Test: 32.00%
Epoch: 100, Loss: 0.0008, Train: 100.00%, Valid: 64.60%, Test: 65.30%, Best Valid: 67.60%, Best Test: 66.60%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 63.60%, Test: 63.60%, Best Valid: 67.60%, Best Test: 66.60%
Epoch: 200, Loss: 0.0001, Train: 100.00%, Valid: 64.00%, Test: 63.60%, Best Valid: 67.60%, Best Test: 66.60%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 64.00%, Test: 63.70%, Best Valid: 67.60%, Best Test: 66.60%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 63.80%, Test: 63.40%, Best Valid: 67.60%, Best Test: 66.60%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 63.60%, Test: 63.00%, Best Valid: 67.60%, Best Test: 66.60%
train_accuracy_list: [0.0, 0.0, 0.0, 0.12142857142857143, 0.14285714285714285, 0.14285714285714285, 0.12142857142857143, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.21428571428571427, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.22142857142857142, 0.32857142857142857, 0.35, 0.3142857142857143, 0.3, 0.32142857142857145, 0.32142857142857145, 0.30714285714285716, 0.4, 0.2642857142857143, 0.2714285714285714, 0.3, 0.3, 0.35, 0.37857142857142856, 0.4142857142857143, 0.4928571428571429, 0.5428571428571428, 0.5642857142857143, 0.6, 0.5928571428571429, 0.5928571428571429, 0.5857142857142857, 0.6214285714285714, 0.6, 0.6285714285714286, 0.6928571428571428, 0.8428571428571429, 0.8428571428571429, 0.8571428571428571, 0.8714285714285714, 0.8857142857142857, 0.8928571428571429, 0.9, 0.9071428571428571, 0.9214285714285714, 0.9285714285714286, 0.95, 0.95, 0.9642857142857143, 0.9785714285714285, 0.9857142857142858, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.0, 0.0, 0.0, 0.14, 0.122, 0.122, 0.148, 0.08, 0.114, 0.316, 0.156, 0.162, 0.122, 0.122, 0.072, 0.072, 0.114, 0.114, 0.114, 0.138, 0.316, 0.316, 0.178, 0.062, 0.058, 0.058, 0.058, 0.07, 0.072, 0.132, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.162, 0.222, 0.3, 0.286, 0.274, 0.268, 0.23, 0.236, 0.256, 0.156, 0.14, 0.176, 0.154, 0.182, 0.248, 0.304, 0.36, 0.416, 0.418, 0.432, 0.464, 0.472, 0.476, 0.474, 0.462, 0.496, 0.57, 0.618, 0.646, 0.636, 0.61, 0.592, 0.584, 0.576, 0.6, 0.638, 0.638, 0.648, 0.672, 0.676, 0.676, 0.674, 0.666, 0.664, 0.652, 0.656, 0.66, 0.656, 0.65, 0.646, 0.644, 0.65, 0.652, 0.654, 0.652, 0.652, 0.65, 0.648, 0.644, 0.646, 0.646, 0.646, 0.646, 0.642, 0.638, 0.638, 0.638, 0.636, 0.636, 0.636, 0.632, 0.634, 0.632, 0.632, 0.632, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.636, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.642, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634]
test_accuracy_list: [0.0, 0.0, 0.0, 0.129, 0.131, 0.13, 0.131, 0.095, 0.103, 0.319, 0.144, 0.149, 0.13, 0.13, 0.091, 0.091, 0.103, 0.103, 0.103, 0.124, 0.319, 0.32, 0.167, 0.067, 0.064, 0.064, 0.064, 0.071, 0.091, 0.157, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.188, 0.219, 0.25, 0.247, 0.244, 0.232, 0.205, 0.217, 0.258, 0.187, 0.16, 0.209, 0.2, 0.207, 0.276, 0.322, 0.36, 0.415, 0.398, 0.41, 0.451, 0.47, 0.475, 0.465, 0.458, 0.493, 0.554, 0.622, 0.634, 0.633, 0.627, 0.6, 0.577, 0.576, 0.605, 0.63, 0.651, 0.664, 0.666, 0.664, 0.66, 0.656, 0.658, 0.659, 0.661, 0.657, 0.654, 0.656, 0.653, 0.654, 0.657, 0.657, 0.656, 0.657, 0.656, 0.653, 0.655, 0.657, 0.654, 0.654, 0.654, 0.654, 0.653, 0.652, 0.652, 0.652, 0.652, 0.652, 0.649, 0.645, 0.645, 0.644, 0.643, 0.643, 0.643, 0.643, 0.642, 0.641, 0.641, 0.64, 0.639, 0.639, 0.639, 0.637, 0.638, 0.638, 0.638, 0.638, 0.638, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.637, 0.637, 0.637, 0.637, 0.637, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.637, 0.637, 0.637, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.638, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.635, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.631, 0.631]
best validation: 0.676
best test: 0.666
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 0
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 16
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.8531, Train: 76.43%, Valid: 61.00%, Test: 60.90%, Best Valid: 61.00%, Best Test: 60.90%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 68.80%, Test: 72.10%, Best Valid: 69.00%, Best Test: 72.40%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 69.20%, Test: 70.80%, Best Valid: 69.20%, Best Test: 72.40%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.60%, Test: 71.00%, Best Valid: 69.20%, Best Test: 72.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 70.90%, Best Valid: 69.20%, Best Test: 72.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 70.70%, Best Valid: 69.20%, Best Test: 72.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 68.20%, Test: 70.60%, Best Valid: 69.20%, Best Test: 72.40%
train_accuracy_list: [0.007142857142857143, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.21428571428571427, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.25, 0.3, 0.2785714285714286, 0.24285714285714285, 0.2714285714285714, 0.2571428571428571, 0.2357142857142857, 0.34285714285714286, 0.4857142857142857, 0.5071428571428571, 0.5428571428571428, 0.5857142857142857, 0.6071428571428571, 0.6428571428571429, 0.7142857142857143, 0.6571428571428571, 0.6714285714285714, 0.7214285714285714, 0.6571428571428571, 0.6857142857142857, 0.7642857142857142, 0.8642857142857143, 0.8428571428571429, 0.8785714285714286, 0.9214285714285714, 0.9214285714285714, 0.9428571428571428, 0.9428571428571428, 0.9928571428571429, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.002, 0.072, 0.072, 0.072, 0.072, 0.072, 0.072, 0.122, 0.122, 0.058, 0.114, 0.114, 0.162, 0.162, 0.162, 0.206, 0.194, 0.316, 0.066, 0.058, 0.058, 0.058, 0.118, 0.122, 0.122, 0.072, 0.072, 0.072, 0.072, 0.124, 0.208, 0.172, 0.186, 0.164, 0.106, 0.096, 0.164, 0.438, 0.49, 0.494, 0.326, 0.344, 0.362, 0.398, 0.358, 0.382, 0.544, 0.562, 0.58, 0.61, 0.548, 0.516, 0.56, 0.638, 0.678, 0.654, 0.646, 0.672, 0.68, 0.67, 0.68, 0.684, 0.678, 0.676, 0.684, 0.688, 0.672, 0.678, 0.676, 0.68, 0.68, 0.674, 0.678, 0.682, 0.68, 0.682, 0.686, 0.682, 0.682, 0.684, 0.686, 0.688, 0.688, 0.688, 0.688, 0.684, 0.686, 0.69, 0.688, 0.688, 0.69, 0.688, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.688, 0.688, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.69, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.688, 0.688, 0.688, 0.688, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684]
test_accuracy_list: [0.001, 0.091, 0.091, 0.091, 0.091, 0.091, 0.091, 0.13, 0.13, 0.064, 0.103, 0.103, 0.149, 0.149, 0.149, 0.174, 0.179, 0.319, 0.067, 0.064, 0.064, 0.064, 0.133, 0.13, 0.13, 0.091, 0.091, 0.091, 0.091, 0.139, 0.223, 0.173, 0.176, 0.146, 0.115, 0.108, 0.197, 0.449, 0.494, 0.515, 0.351, 0.374, 0.395, 0.418, 0.38, 0.398, 0.561, 0.568, 0.578, 0.609, 0.571, 0.518, 0.567, 0.661, 0.683, 0.671, 0.663, 0.681, 0.691, 0.7, 0.709, 0.715, 0.712, 0.706, 0.712, 0.716, 0.717, 0.706, 0.71, 0.712, 0.709, 0.71, 0.711, 0.705, 0.705, 0.704, 0.714, 0.717, 0.722, 0.723, 0.724, 0.722, 0.72, 0.72, 0.722, 0.721, 0.719, 0.717, 0.717, 0.717, 0.715, 0.719, 0.72, 0.72, 0.718, 0.717, 0.717, 0.719, 0.719, 0.721, 0.722, 0.72, 0.718, 0.717, 0.716, 0.715, 0.713, 0.712, 0.714, 0.714, 0.713, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.711, 0.711, 0.71, 0.71, 0.711, 0.71, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.71, 0.71, 0.71, 0.71, 0.711, 0.711, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706]
best validation: 0.692
best test: 0.724
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 0
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 16
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.4262, Train: 69.29%, Valid: 40.80%, Test: 42.40%, Best Valid: 49.40%, Best Test: 51.30%
Epoch: 100, Loss: 0.0002, Train: 100.00%, Valid: 64.00%, Test: 61.00%, Best Valid: 67.00%, Best Test: 67.80%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 63.00%, Test: 60.50%, Best Valid: 67.00%, Best Test: 67.80%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 63.40%, Test: 60.60%, Best Valid: 67.00%, Best Test: 67.80%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 63.40%, Test: 60.70%, Best Valid: 67.00%, Best Test: 67.80%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 63.60%, Test: 60.80%, Best Valid: 67.00%, Best Test: 67.80%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 63.40%, Test: 60.80%, Best Valid: 67.00%, Best Test: 67.80%
train_accuracy_list: [0.05714285714285714, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.14285714285714285, 0.1357142857142857, 0.14285714285714285, 0.15, 0.1357142857142857, 0.14285714285714285, 0.17857142857142858, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.14285714285714285, 0.15, 0.22142857142857142, 0.14285714285714285, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.34285714285714286, 0.40714285714285714, 0.37857142857142856, 0.4142857142857143, 0.40714285714285714, 0.4857142857142857, 0.5142857142857142, 0.5214285714285715, 0.5142857142857142, 0.4714285714285714, 0.4785714285714286, 0.5071428571428571, 0.5142857142857142, 0.5642857142857143, 0.6, 0.6428571428571429, 0.6785714285714286, 0.6928571428571428, 0.7071428571428572, 0.7142857142857143, 0.75, 0.7571428571428571, 0.8142857142857143, 0.8642857142857143, 0.8642857142857143, 0.9214285714285714, 0.9285714285714286, 0.9428571428571428, 0.9642857142857143, 0.9785714285714285, 0.9785714285714285, 0.9785714285714285, 0.9785714285714285, 0.9785714285714285, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.02, 0.07, 0.07, 0.072, 0.072, 0.072, 0.072, 0.076, 0.122, 0.15, 0.162, 0.322, 0.168, 0.156, 0.164, 0.12, 0.114, 0.074, 0.058, 0.096, 0.162, 0.166, 0.146, 0.078, 0.088, 0.124, 0.122, 0.122, 0.122, 0.124, 0.062, 0.076, 0.144, 0.238, 0.298, 0.328, 0.304, 0.362, 0.432, 0.494, 0.368, 0.32, 0.322, 0.336, 0.336, 0.334, 0.332, 0.33, 0.366, 0.408, 0.458, 0.516, 0.576, 0.604, 0.624, 0.628, 0.632, 0.598, 0.594, 0.594, 0.602, 0.62, 0.636, 0.654, 0.67, 0.664, 0.656, 0.654, 0.656, 0.652, 0.648, 0.644, 0.64, 0.638, 0.636, 0.634, 0.632, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.642, 0.646, 0.644, 0.64, 0.642, 0.642, 0.64, 0.64, 0.64, 0.642, 0.64, 0.638, 0.638, 0.64, 0.64, 0.64, 0.64, 0.638, 0.638, 0.638, 0.638, 0.636, 0.636, 0.634, 0.634, 0.632, 0.632, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.636, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.632, 0.632, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.634, 0.634, 0.634]
test_accuracy_list: [0.014, 0.09, 0.091, 0.091, 0.091, 0.091, 0.091, 0.094, 0.13, 0.143, 0.15, 0.317, 0.147, 0.145, 0.128, 0.103, 0.103, 0.065, 0.064, 0.112, 0.15, 0.16, 0.153, 0.096, 0.118, 0.133, 0.13, 0.13, 0.13, 0.136, 0.069, 0.101, 0.164, 0.224, 0.256, 0.295, 0.291, 0.372, 0.472, 0.513, 0.369, 0.295, 0.333, 0.339, 0.336, 0.342, 0.34, 0.349, 0.383, 0.424, 0.481, 0.535, 0.563, 0.598, 0.616, 0.639, 0.637, 0.608, 0.589, 0.581, 0.599, 0.621, 0.658, 0.669, 0.678, 0.674, 0.658, 0.656, 0.658, 0.645, 0.638, 0.635, 0.629, 0.624, 0.625, 0.625, 0.622, 0.618, 0.618, 0.619, 0.621, 0.621, 0.617, 0.614, 0.615, 0.612, 0.614, 0.615, 0.616, 0.616, 0.616, 0.616, 0.615, 0.615, 0.616, 0.616, 0.613, 0.614, 0.612, 0.61, 0.609, 0.609, 0.609, 0.609, 0.609, 0.609, 0.609, 0.609, 0.608, 0.608, 0.608, 0.608, 0.608, 0.607, 0.608, 0.608, 0.608, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.606, 0.606, 0.606, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.605, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.606, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.608, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607, 0.607]
best validation: 0.67
best test: 0.678
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 1
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 32
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.4958, Train: 86.43%, Valid: 66.60%, Test: 66.20%, Best Valid: 66.60%, Best Test: 66.20%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40%, Test: 75.30%, Best Valid: 73.40%, Best Test: 75.30%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 73.40%, Test: 75.30%, Best Valid: 73.60%, Best Test: 75.30%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 73.00%, Test: 75.10%, Best Valid: 73.60%, Best Test: 75.30%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 73.40%, Test: 74.80%, Best Valid: 73.60%, Best Test: 75.30%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 72.80%, Test: 74.70%, Best Valid: 73.60%, Best Test: 75.30%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 72.60%, Test: 74.50%, Best Valid: 73.60%, Best Test: 75.30%
train_accuracy_list: [0.02142857142857143, 0.02142857142857143, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17142857142857143, 0.15, 0.17142857142857143, 0.20714285714285716, 0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.21428571428571427, 0.17857142857142858, 0.17857142857142858, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.35714285714285715, 0.45, 0.32857142857142857, 0.30714285714285716, 0.37857142857142856, 0.5357142857142857, 0.7214285714285714, 0.7285714285714285, 0.5428571428571428, 0.5785714285714286, 0.6, 0.6214285714285714, 0.6714285714285714, 0.7571428571428571, 0.8642857142857143, 0.8142857142857143, 0.8071428571428572, 0.8071428571428572, 0.8214285714285714, 0.8071428571428572, 0.8642857142857143, 0.9, 0.9285714285714286, 0.95, 0.9571428571428572, 0.9642857142857143, 0.9714285714285714, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.11, 0.128, 0.158, 0.162, 0.162, 0.162, 0.156, 0.114, 0.072, 0.122, 0.122, 0.058, 0.144, 0.162, 0.188, 0.156, 0.156, 0.156, 0.128, 0.12, 0.12, 0.116, 0.098, 0.078, 0.072, 0.072, 0.074, 0.07, 0.07, 0.104, 0.122, 0.122, 0.122, 0.122, 0.122, 0.306, 0.292, 0.14, 0.122, 0.134, 0.252, 0.532, 0.532, 0.414, 0.424, 0.396, 0.39, 0.428, 0.536, 0.666, 0.662, 0.664, 0.676, 0.674, 0.662, 0.704, 0.714, 0.71, 0.714, 0.698, 0.686, 0.708, 0.71, 0.714, 0.712, 0.71, 0.712, 0.71, 0.706, 0.696, 0.696, 0.686, 0.688, 0.694, 0.696, 0.702, 0.706, 0.704, 0.71, 0.714, 0.714, 0.716, 0.716, 0.718, 0.724, 0.722, 0.724, 0.724, 0.726, 0.728, 0.728, 0.73, 0.73, 0.73, 0.73, 0.73, 0.728, 0.732, 0.732, 0.734, 0.734, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.73, 0.73, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.732, 0.732, 0.732, 0.732, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.734, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73]
test_accuracy_list: [0.11, 0.124, 0.145, 0.149, 0.149, 0.149, 0.144, 0.103, 0.091, 0.13, 0.13, 0.064, 0.135, 0.149, 0.165, 0.144, 0.144, 0.144, 0.122, 0.105, 0.104, 0.101, 0.104, 0.102, 0.09, 0.091, 0.077, 0.076, 0.077, 0.116, 0.13, 0.13, 0.13, 0.13, 0.13, 0.325, 0.318, 0.173, 0.146, 0.171, 0.289, 0.536, 0.522, 0.386, 0.399, 0.399, 0.388, 0.411, 0.506, 0.662, 0.683, 0.673, 0.68, 0.686, 0.68, 0.708, 0.736, 0.735, 0.739, 0.726, 0.726, 0.737, 0.746, 0.746, 0.739, 0.743, 0.743, 0.738, 0.734, 0.732, 0.73, 0.729, 0.729, 0.728, 0.73, 0.732, 0.733, 0.736, 0.739, 0.743, 0.741, 0.743, 0.743, 0.743, 0.743, 0.746, 0.745, 0.745, 0.746, 0.745, 0.745, 0.747, 0.749, 0.75, 0.751, 0.752, 0.752, 0.751, 0.752, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.752, 0.752, 0.752, 0.752, 0.752, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.753, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.751, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.751, 0.751, 0.751, 0.751, 0.751, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.745, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744, 0.744]
best validation: 0.736
best test: 0.753
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 1
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 32
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.6052, Train: 75.71%, Valid: 50.00%, Test: 47.20%, Best Valid: 59.80%, Best Test: 58.90%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 72.20%, Test: 73.40%, Best Valid: 73.80%, Best Test: 73.40%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 72.60%, Test: 73.00%, Best Valid: 73.80%, Best Test: 73.40%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 73.00%, Test: 73.10%, Best Valid: 73.80%, Best Test: 73.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 72.80%, Test: 72.60%, Best Valid: 73.80%, Best Test: 73.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 73.00%, Test: 72.50%, Best Valid: 73.80%, Best Test: 73.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 73.60%, Test: 72.60%, Best Valid: 73.80%, Best Test: 73.40%
train_accuracy_list: [0.0, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.19285714285714287, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.15, 0.14285714285714285, 0.16428571428571428, 0.21428571428571427, 0.17142857142857143, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.17142857142857143, 0.15, 0.17142857142857143, 0.17142857142857143, 0.17142857142857143, 0.20714285714285716, 0.32142857142857145, 0.39285714285714285, 0.5071428571428571, 0.5428571428571428, 0.5714285714285714, 0.6142857142857143, 0.6285714285714286, 0.6714285714285714, 0.7928571428571428, 0.8071428571428572, 0.7571428571428571, 0.7357142857142858, 0.75, 0.7642857142857142, 0.7785714285714286, 0.8, 0.8142857142857143, 0.8285714285714286, 0.8571428571428571, 0.9, 0.9142857142857143, 0.9214285714285714, 0.9214285714285714, 0.9285714285714286, 0.9428571428571428, 0.9357142857142857, 0.95, 0.9571428571428572, 0.9857142857142858, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.0, 0.108, 0.162, 0.162, 0.162, 0.112, 0.122, 0.056, 0.316, 0.072, 0.162, 0.116, 0.122, 0.122, 0.058, 0.072, 0.072, 0.072, 0.316, 0.316, 0.316, 0.316, 0.322, 0.164, 0.162, 0.174, 0.178, 0.134, 0.128, 0.126, 0.12, 0.12, 0.124, 0.13, 0.106, 0.09, 0.078, 0.078, 0.078, 0.12, 0.224, 0.276, 0.28, 0.42, 0.502, 0.544, 0.558, 0.598, 0.524, 0.5, 0.48, 0.478, 0.5, 0.506, 0.514, 0.532, 0.56, 0.588, 0.614, 0.65, 0.682, 0.676, 0.68, 0.686, 0.704, 0.702, 0.704, 0.708, 0.722, 0.724, 0.726, 0.722, 0.728, 0.732, 0.726, 0.728, 0.728, 0.732, 0.73, 0.734, 0.734, 0.732, 0.734, 0.73, 0.736, 0.738, 0.736, 0.73, 0.732, 0.728, 0.732, 0.734, 0.73, 0.732, 0.732, 0.726, 0.724, 0.72, 0.722, 0.722, 0.724, 0.728, 0.726, 0.726, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.728, 0.728, 0.728, 0.726, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.734, 0.734, 0.734, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736, 0.736]
test_accuracy_list: [0.0, 0.129, 0.149, 0.149, 0.149, 0.136, 0.13, 0.069, 0.319, 0.091, 0.149, 0.113, 0.13, 0.13, 0.064, 0.091, 0.091, 0.091, 0.319, 0.319, 0.319, 0.319, 0.328, 0.149, 0.149, 0.159, 0.189, 0.148, 0.133, 0.13, 0.133, 0.132, 0.139, 0.145, 0.137, 0.117, 0.105, 0.099, 0.102, 0.15, 0.244, 0.299, 0.286, 0.445, 0.497, 0.525, 0.544, 0.589, 0.524, 0.472, 0.456, 0.46, 0.48, 0.505, 0.526, 0.529, 0.548, 0.58, 0.6, 0.638, 0.665, 0.672, 0.672, 0.682, 0.696, 0.7, 0.712, 0.718, 0.721, 0.715, 0.717, 0.711, 0.721, 0.723, 0.727, 0.728, 0.732, 0.733, 0.732, 0.732, 0.729, 0.731, 0.728, 0.727, 0.725, 0.728, 0.728, 0.725, 0.726, 0.725, 0.726, 0.727, 0.729, 0.732, 0.731, 0.732, 0.73, 0.731, 0.734, 0.734, 0.733, 0.73, 0.729, 0.729, 0.729, 0.73, 0.731, 0.729, 0.728, 0.728, 0.728, 0.727, 0.727, 0.727, 0.727, 0.727, 0.728, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.728, 0.728, 0.728, 0.729, 0.729, 0.73, 0.73, 0.73, 0.73, 0.731, 0.731, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.731, 0.73, 0.73, 0.73, 0.73, 0.73, 0.729, 0.729, 0.729, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.729, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.731, 0.73, 0.73, 0.729, 0.729, 0.729, 0.729, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.727, 0.727, 0.727, 0.728, 0.728, 0.727, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.725, 0.725, 0.725, 0.725, 0.725, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.724, 0.724, 0.724, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.726, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.728, 0.728, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.727, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728]
best validation: 0.738
best test: 0.734
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 1
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 32
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.0672, Train: 87.14%, Valid: 62.00%, Test: 64.60%, Best Valid: 68.20%, Best Test: 67.70%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 68.40%, Test: 69.70%, Best Valid: 70.60%, Best Test: 71.60%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 68.80%, Best Valid: 70.60%, Best Test: 71.60%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.60%, Test: 69.30%, Best Valid: 70.60%, Best Test: 71.60%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 69.20%, Best Valid: 70.60%, Best Test: 71.60%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 69.20%, Best Valid: 70.60%, Best Test: 71.60%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 69.30%, Best Valid: 70.60%, Best Test: 71.60%
train_accuracy_list: [0.007142857142857143, 0.14285714285714285, 0.15, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.20714285714285716, 0.20714285714285716, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.21428571428571427, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.20714285714285716, 0.15, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15714285714285714, 0.17142857142857143, 0.20714285714285716, 0.21428571428571427, 0.2714285714285714, 0.15714285714285714, 0.15714285714285714, 0.20714285714285716, 0.2857142857142857, 0.15714285714285714, 0.16428571428571428, 0.22142857142857142, 0.40714285714285714, 0.36428571428571427, 0.45714285714285713, 0.6285714285714286, 0.6714285714285714, 0.6285714285714286, 0.7357142857142858, 0.7785714285714286, 0.7285714285714285, 0.7928571428571428, 0.8, 0.8714285714285714, 0.8714285714285714, 0.8928571428571429, 0.9071428571428571, 0.9142857142857143, 0.9285714285714286, 0.9428571428571428, 0.9642857142857143, 0.9642857142857143, 0.9714285714285714, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.0, 0.07, 0.07, 0.086, 0.122, 0.072, 0.058, 0.162, 0.172, 0.286, 0.122, 0.076, 0.072, 0.072, 0.058, 0.058, 0.102, 0.162, 0.162, 0.162, 0.182, 0.124, 0.122, 0.124, 0.128, 0.142, 0.158, 0.176, 0.184, 0.166, 0.074, 0.072, 0.078, 0.098, 0.06, 0.06, 0.072, 0.168, 0.144, 0.156, 0.37, 0.398, 0.392, 0.538, 0.636, 0.662, 0.682, 0.638, 0.608, 0.62, 0.618, 0.614, 0.626, 0.64, 0.664, 0.652, 0.646, 0.67, 0.682, 0.668, 0.686, 0.688, 0.69, 0.668, 0.664, 0.666, 0.672, 0.666, 0.658, 0.652, 0.684, 0.684, 0.67, 0.662, 0.678, 0.698, 0.698, 0.692, 0.69, 0.69, 0.696, 0.7, 0.706, 0.7, 0.692, 0.686, 0.68, 0.674, 0.674, 0.67, 0.67, 0.67, 0.67, 0.672, 0.674, 0.678, 0.682, 0.682, 0.682, 0.684, 0.69, 0.692, 0.698, 0.696, 0.694, 0.692, 0.692, 0.69, 0.688, 0.688, 0.682, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.678, 0.678, 0.674, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69]
test_accuracy_list: [0.001, 0.091, 0.091, 0.113, 0.13, 0.091, 0.064, 0.149, 0.138, 0.282, 0.13, 0.1, 0.091, 0.091, 0.064, 0.064, 0.112, 0.149, 0.149, 0.149, 0.166, 0.13, 0.13, 0.13, 0.131, 0.138, 0.145, 0.164, 0.161, 0.167, 0.092, 0.092, 0.102, 0.123, 0.065, 0.066, 0.079, 0.208, 0.162, 0.173, 0.366, 0.388, 0.388, 0.541, 0.651, 0.657, 0.677, 0.652, 0.645, 0.646, 0.638, 0.65, 0.655, 0.693, 0.705, 0.683, 0.683, 0.708, 0.699, 0.695, 0.705, 0.71, 0.708, 0.697, 0.693, 0.7, 0.697, 0.689, 0.683, 0.683, 0.698, 0.699, 0.694, 0.687, 0.701, 0.701, 0.715, 0.714, 0.716, 0.716, 0.714, 0.714, 0.707, 0.705, 0.702, 0.7, 0.694, 0.694, 0.693, 0.687, 0.686, 0.685, 0.686, 0.689, 0.693, 0.696, 0.696, 0.697, 0.696, 0.697, 0.697, 0.698, 0.699, 0.702, 0.702, 0.702, 0.703, 0.704, 0.703, 0.703, 0.703, 0.703, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.701, 0.701, 0.699, 0.698, 0.697, 0.697, 0.697, 0.695, 0.695, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.691, 0.69, 0.69, 0.69, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.688, 0.688, 0.688, 0.688, 0.688, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.691, 0.691, 0.691, 0.691, 0.691, 0.691, 0.691, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694]
best validation: 0.706
best test: 0.716
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 2
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 64
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.3215, Train: 98.57%, Valid: 66.40%, Test: 64.20%, Best Valid: 71.40%, Best Test: 73.00%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.40%, Test: 71.80%, Best Valid: 72.80%, Best Test: 73.00%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 72.20%, Test: 71.50%, Best Valid: 72.80%, Best Test: 73.00%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 72.20%, Test: 71.40%, Best Valid: 72.80%, Best Test: 73.00%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 72.00%, Test: 71.40%, Best Valid: 72.80%, Best Test: 73.00%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 72.20%, Test: 71.40%, Best Valid: 72.80%, Best Test: 73.00%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 72.20%, Test: 71.60%, Best Valid: 72.80%, Best Test: 73.00%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.19285714285714287, 0.2642857142857143, 0.36428571428571427, 0.37142857142857144, 0.29285714285714287, 0.2857142857142857, 0.37142857142857144, 0.22142857142857142, 0.22857142857142856, 0.36428571428571427, 0.5642857142857143, 0.6214285714285714, 0.6357142857142857, 0.6428571428571429, 0.6214285714285714, 0.6857142857142857, 0.7285714285714285, 0.7642857142857142, 0.8285714285714286, 0.8714285714285714, 0.9071428571428571, 0.8571428571428571, 0.8357142857142857, 0.85, 0.9142857142857143, 0.9571428571428572, 0.9785714285714285, 0.9857142857142858, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.306, 0.114, 0.114, 0.114, 0.114, 0.314, 0.122, 0.156, 0.072, 0.162, 0.314, 0.316, 0.308, 0.122, 0.122, 0.126, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.116, 0.116, 0.182, 0.232, 0.17, 0.154, 0.356, 0.33, 0.33, 0.362, 0.492, 0.534, 0.458, 0.424, 0.416, 0.448, 0.47, 0.492, 0.518, 0.582, 0.688, 0.692, 0.71, 0.698, 0.714, 0.714, 0.688, 0.664, 0.7, 0.72, 0.714, 0.714, 0.724, 0.726, 0.716, 0.722, 0.724, 0.716, 0.718, 0.72, 0.714, 0.706, 0.706, 0.706, 0.71, 0.712, 0.716, 0.716, 0.722, 0.724, 0.728, 0.728, 0.726, 0.728, 0.726, 0.724, 0.724, 0.724, 0.724, 0.722, 0.722, 0.72, 0.72, 0.718, 0.718, 0.718, 0.72, 0.72, 0.72, 0.722, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.724, 0.724, 0.724, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722]
test_accuracy_list: [0.315, 0.103, 0.103, 0.103, 0.103, 0.324, 0.13, 0.144, 0.091, 0.149, 0.318, 0.319, 0.324, 0.13, 0.13, 0.132, 0.104, 0.103, 0.103, 0.103, 0.103, 0.103, 0.113, 0.108, 0.188, 0.241, 0.184, 0.167, 0.375, 0.338, 0.339, 0.373, 0.493, 0.535, 0.452, 0.424, 0.402, 0.417, 0.447, 0.481, 0.52, 0.608, 0.716, 0.723, 0.72, 0.706, 0.73, 0.717, 0.683, 0.642, 0.67, 0.704, 0.696, 0.698, 0.712, 0.719, 0.722, 0.718, 0.715, 0.711, 0.711, 0.708, 0.71, 0.707, 0.705, 0.706, 0.711, 0.712, 0.712, 0.715, 0.715, 0.719, 0.721, 0.722, 0.721, 0.72, 0.721, 0.721, 0.722, 0.723, 0.721, 0.719, 0.719, 0.719, 0.719, 0.72, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.714, 0.714, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716]
best validation: 0.728
best test: 0.73
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 2
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 64
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.7132, Train: 90.71%, Valid: 60.00%, Test: 62.70%, Best Valid: 60.00%, Best Test: 62.70%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 68.30%, Best Valid: 70.20%, Best Test: 70.20%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 68.50%, Best Valid: 70.20%, Best Test: 70.20%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 68.70%, Best Valid: 70.20%, Best Test: 70.20%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.50%, Best Valid: 70.20%, Best Test: 70.20%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 68.50%, Best Valid: 70.20%, Best Test: 70.20%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 69.60%, Test: 68.80%, Best Valid: 70.20%, Best Test: 70.20%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.2357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.2, 0.19285714285714287, 0.22142857142857142, 0.24285714285714285, 0.21428571428571427, 0.19285714285714287, 0.20714285714285716, 0.3142857142857143, 0.29285714285714287, 0.4142857142857143, 0.45714285714285713, 0.2642857142857143, 0.2642857142857143, 0.32857142857142857, 0.5, 0.6285714285714286, 0.6714285714285714, 0.5571428571428572, 0.5785714285714286, 0.6, 0.6071428571428571, 0.6857142857142857, 0.7214285714285714, 0.7642857142857142, 0.7928571428571428, 0.8571428571428571, 0.9071428571428571, 0.9071428571428571, 0.9071428571428571, 0.9142857142857143, 0.9285714285714286, 0.9428571428571428, 0.9571428571428572, 0.9785714285714285, 0.9857142857142858, 0.9857142857142858, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.072, 0.072, 0.072, 0.072, 0.072, 0.162, 0.142, 0.316, 0.114, 0.058, 0.122, 0.074, 0.072, 0.166, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.164, 0.096, 0.078, 0.088, 0.13, 0.126, 0.122, 0.14, 0.218, 0.214, 0.214, 0.274, 0.122, 0.122, 0.162, 0.24, 0.362, 0.478, 0.504, 0.51, 0.522, 0.568, 0.582, 0.564, 0.558, 0.52, 0.536, 0.58, 0.6, 0.61, 0.646, 0.648, 0.642, 0.674, 0.656, 0.658, 0.678, 0.676, 0.694, 0.698, 0.702, 0.7, 0.692, 0.69, 0.688, 0.68, 0.684, 0.684, 0.688, 0.686, 0.686, 0.686, 0.678, 0.676, 0.676, 0.676, 0.676, 0.674, 0.674, 0.676, 0.68, 0.684, 0.684, 0.684, 0.684, 0.682, 0.684, 0.684, 0.684, 0.686, 0.684, 0.684, 0.68, 0.68, 0.68, 0.678, 0.68, 0.68, 0.68, 0.68, 0.684, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.684, 0.68, 0.68, 0.68, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.69, 0.69, 0.688, 0.688, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.688, 0.69, 0.696, 0.698, 0.696, 0.694, 0.696, 0.698, 0.696, 0.696, 0.694, 0.694, 0.694, 0.694, 0.694, 0.696, 0.696, 0.696, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.694, 0.696, 0.696, 0.696, 0.692, 0.69, 0.692, 0.692, 0.692, 0.692, 0.69, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69]
test_accuracy_list: [0.091, 0.091, 0.091, 0.091, 0.091, 0.149, 0.141, 0.319, 0.103, 0.064, 0.13, 0.098, 0.091, 0.181, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.152, 0.106, 0.073, 0.088, 0.138, 0.14, 0.135, 0.147, 0.201, 0.211, 0.225, 0.231, 0.122, 0.123, 0.139, 0.21, 0.362, 0.504, 0.488, 0.534, 0.555, 0.579, 0.59, 0.586, 0.581, 0.538, 0.557, 0.604, 0.627, 0.645, 0.676, 0.682, 0.678, 0.701, 0.682, 0.674, 0.699, 0.702, 0.701, 0.699, 0.702, 0.697, 0.689, 0.694, 0.686, 0.684, 0.685, 0.687, 0.686, 0.686, 0.686, 0.683, 0.684, 0.684, 0.681, 0.683, 0.683, 0.683, 0.683, 0.685, 0.684, 0.686, 0.687, 0.687, 0.687, 0.687, 0.686, 0.684, 0.683, 0.682, 0.682, 0.683, 0.682, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.682, 0.682, 0.683, 0.683, 0.682, 0.683, 0.683, 0.686, 0.687, 0.687, 0.687, 0.688, 0.688, 0.688, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.688, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.686, 0.686, 0.686, 0.686, 0.686, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.687, 0.687, 0.687, 0.687, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.689, 0.688, 0.688, 0.689, 0.69, 0.69, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.694, 0.695, 0.693, 0.693, 0.693, 0.693, 0.694, 0.694, 0.693, 0.695, 0.694, 0.693, 0.692, 0.691, 0.691, 0.691, 0.69, 0.691, 0.69, 0.69, 0.69, 0.69, 0.691, 0.689, 0.69, 0.69, 0.69, 0.689, 0.69, 0.693, 0.689, 0.69, 0.69]
best validation: 0.702
best test: 0.702
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 2
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 64
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.8573, Train: 97.14%, Valid: 74.80%, Test: 74.40%, Best Valid: 74.80%, Best Test: 74.40%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.60%, Test: 71.10%, Best Valid: 77.20%, Best Test: 74.90%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 76.20%, Test: 71.60%, Best Valid: 77.20%, Best Test: 74.90%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 76.20%, Test: 71.60%, Best Valid: 77.20%, Best Test: 74.90%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 76.40%, Test: 71.90%, Best Valid: 77.20%, Best Test: 74.90%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 76.40%, Test: 72.00%, Best Valid: 77.20%, Best Test: 74.90%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 76.40%, Test: 71.70%, Best Valid: 77.20%, Best Test: 74.90%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15, 0.15714285714285714, 0.17142857142857143, 0.17857142857142858, 0.17142857142857143, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.2357142857142857, 0.4357142857142857, 0.38571428571428573, 0.4928571428571429, 0.2785714285714286, 0.2642857142857143, 0.29285714285714287, 0.3142857142857143, 0.4714285714285714, 0.4785714285714286, 0.4857142857142857, 0.5214285714285715, 0.5714285714285714, 0.6428571428571429, 0.6928571428571428, 0.7285714285714285, 0.7642857142857142, 0.8428571428571429, 0.8857142857142857, 0.9142857142857143, 0.9214285714285714, 0.9714285714285714, 0.9642857142857143, 0.9642857142857143, 0.95, 0.9714285714285714, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.156, 0.156, 0.156, 0.156, 0.114, 0.072, 0.122, 0.162, 0.316, 0.156, 0.156, 0.156, 0.058, 0.072, 0.072, 0.072, 0.072, 0.072, 0.072, 0.072, 0.072, 0.07, 0.076, 0.084, 0.132, 0.122, 0.122, 0.124, 0.134, 0.174, 0.186, 0.3, 0.2, 0.206, 0.236, 0.28, 0.342, 0.392, 0.368, 0.416, 0.408, 0.406, 0.444, 0.518, 0.558, 0.628, 0.722, 0.728, 0.73, 0.748, 0.758, 0.716, 0.714, 0.738, 0.772, 0.762, 0.754, 0.764, 0.76, 0.76, 0.76, 0.76, 0.756, 0.752, 0.738, 0.734, 0.744, 0.748, 0.758, 0.756, 0.762, 0.76, 0.758, 0.754, 0.758, 0.758, 0.758, 0.758, 0.758, 0.76, 0.766, 0.768, 0.764, 0.762, 0.762, 0.76, 0.76, 0.76, 0.76, 0.762, 0.762, 0.76, 0.758, 0.756, 0.756, 0.754, 0.754, 0.756, 0.756, 0.756, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.758, 0.758, 0.758, 0.756, 0.756, 0.756, 0.758, 0.758, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.764, 0.762, 0.762, 0.762, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762, 0.762]
test_accuracy_list: [0.144, 0.144, 0.144, 0.144, 0.103, 0.091, 0.13, 0.149, 0.319, 0.144, 0.144, 0.144, 0.064, 0.094, 0.091, 0.091, 0.091, 0.091, 0.091, 0.091, 0.092, 0.093, 0.096, 0.12, 0.149, 0.13, 0.13, 0.133, 0.155, 0.166, 0.168, 0.268, 0.189, 0.193, 0.213, 0.252, 0.351, 0.396, 0.385, 0.442, 0.428, 0.423, 0.461, 0.527, 0.587, 0.649, 0.737, 0.736, 0.734, 0.744, 0.749, 0.723, 0.706, 0.733, 0.744, 0.736, 0.723, 0.728, 0.732, 0.734, 0.732, 0.724, 0.724, 0.715, 0.709, 0.707, 0.701, 0.695, 0.702, 0.707, 0.708, 0.708, 0.705, 0.701, 0.698, 0.695, 0.696, 0.698, 0.699, 0.701, 0.704, 0.704, 0.705, 0.709, 0.709, 0.714, 0.715, 0.715, 0.712, 0.711, 0.71, 0.71, 0.708, 0.708, 0.709, 0.71, 0.71, 0.71, 0.71, 0.711, 0.712, 0.712, 0.713, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.713, 0.712, 0.713, 0.713, 0.712, 0.712, 0.712, 0.712, 0.712, 0.713, 0.713, 0.714, 0.714, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.717, 0.717, 0.717, 0.717, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.72, 0.72, 0.72, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.719, 0.718, 0.718, 0.718, 0.718, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.717, 0.717, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.717, 0.717]
best validation: 0.772
best test: 0.749
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 3
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 128
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.6975, Train: 94.29%, Valid: 66.00%, Test: 67.60%, Best Valid: 69.00%, Best Test: 70.00%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00%, Test: 72.40%, Best Valid: 73.00%, Best Test: 72.50%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 72.40%, Test: 72.30%, Best Valid: 73.00%, Best Test: 72.50%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 72.20%, Test: 72.40%, Best Valid: 73.00%, Best Test: 72.50%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 71.60%, Test: 72.40%, Best Valid: 73.00%, Best Test: 72.50%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 71.60%, Test: 72.40%, Best Valid: 73.00%, Best Test: 72.50%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 71.20%, Test: 72.40%, Best Valid: 73.00%, Best Test: 72.50%
train_accuracy_list: [0.24285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.30714285714285716, 0.32857142857142857, 0.17857142857142858, 0.16428571428571428, 0.17857142857142858, 0.2357142857142857, 0.35714285714285715, 0.37142857142857144, 0.45714285714285713, 0.4142857142857143, 0.4714285714285714, 0.42142857142857143, 0.38571428571428573, 0.42857142857142855, 0.5357142857142857, 0.7142857142857143, 0.7214285714285714, 0.6785714285714286, 0.7, 0.75, 0.8071428571428572, 0.8785714285714286, 0.9, 0.9285714285714286, 0.9428571428571428, 0.9428571428571428, 0.9357142857142857, 0.9428571428571428, 0.9571428571428572, 0.9642857142857143, 0.9642857142857143, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.16, 0.162, 0.162, 0.162, 0.122, 0.316, 0.156, 0.114, 0.162, 0.162, 0.122, 0.122, 0.122, 0.132, 0.316, 0.316, 0.316, 0.316, 0.316, 0.316, 0.316, 0.316, 0.318, 0.314, 0.256, 0.216, 0.166, 0.166, 0.166, 0.198, 0.268, 0.198, 0.278, 0.214, 0.276, 0.38, 0.36, 0.37, 0.406, 0.504, 0.454, 0.462, 0.458, 0.486, 0.51, 0.602, 0.69, 0.68, 0.682, 0.66, 0.642, 0.688, 0.714, 0.702, 0.726, 0.704, 0.718, 0.724, 0.724, 0.714, 0.712, 0.718, 0.718, 0.718, 0.718, 0.714, 0.716, 0.72, 0.72, 0.722, 0.726, 0.726, 0.728, 0.73, 0.73, 0.73, 0.726, 0.73, 0.728, 0.728, 0.724, 0.718, 0.718, 0.714, 0.714, 0.714, 0.718, 0.718, 0.718, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.718, 0.716, 0.716, 0.716, 0.716, 0.716, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708]
test_accuracy_list: [0.154, 0.149, 0.149, 0.149, 0.13, 0.319, 0.144, 0.103, 0.149, 0.149, 0.13, 0.13, 0.13, 0.148, 0.318, 0.319, 0.319, 0.319, 0.319, 0.319, 0.319, 0.319, 0.319, 0.316, 0.285, 0.205, 0.151, 0.15, 0.154, 0.181, 0.231, 0.199, 0.278, 0.24, 0.323, 0.378, 0.361, 0.379, 0.443, 0.528, 0.448, 0.413, 0.438, 0.471, 0.5, 0.64, 0.7, 0.686, 0.691, 0.676, 0.663, 0.687, 0.703, 0.696, 0.703, 0.707, 0.715, 0.723, 0.724, 0.714, 0.71, 0.711, 0.716, 0.713, 0.714, 0.713, 0.713, 0.715, 0.718, 0.717, 0.719, 0.717, 0.717, 0.717, 0.717, 0.717, 0.721, 0.724, 0.723, 0.72, 0.719, 0.72, 0.722, 0.722, 0.722, 0.722, 0.724, 0.724, 0.724, 0.722, 0.723, 0.724, 0.725, 0.725, 0.725, 0.725, 0.725, 0.724, 0.723, 0.724, 0.724, 0.724, 0.724, 0.724, 0.725, 0.725, 0.725, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.723, 0.723, 0.722, 0.722, 0.722, 0.722, 0.723, 0.723, 0.723, 0.723, 0.723, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.724, 0.725, 0.725, 0.725, 0.725, 0.725, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.725, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.724, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723]
best validation: 0.73
best test: 0.725
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 3
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 128
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.1025, Train: 99.29%, Valid: 71.60%, Test: 72.90%, Best Valid: 71.60%, Best Test: 73.10%
Epoch: 100, Loss: 0.0004, Train: 100.00%, Valid: 73.80%, Test: 73.20%, Best Valid: 74.40%, Best Test: 74.60%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 74.80%, Test: 73.70%, Best Valid: 75.20%, Best Test: 74.60%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 75.60%, Test: 73.80%, Best Valid: 75.60%, Best Test: 74.60%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 74.80%, Test: 74.60%, Best Valid: 75.60%, Best Test: 74.70%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 75.00%, Test: 74.70%, Best Valid: 75.60%, Best Test: 74.70%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 75.40%, Test: 74.70%, Best Valid: 75.60%, Best Test: 74.80%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.19285714285714287, 0.2357142857142857, 0.2642857142857143, 0.17142857142857143, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.2, 0.4928571428571429, 0.36428571428571427, 0.35714285714285715, 0.37857142857142856, 0.42857142857142855, 0.6357142857142857, 0.5714285714285714, 0.5857142857142857, 0.6714285714285714, 0.7142857142857143, 0.6857142857142857, 0.6928571428571428, 0.7142857142857143, 0.7571428571428571, 0.8, 0.8285714285714286, 0.8285714285714286, 0.8571428571428571, 0.9428571428571428, 0.95, 0.95, 0.9642857142857143, 0.9785714285714285, 0.9857142857142858, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 0.9714285714285714, 1.0, 0.9714285714285714, 0.9785714285714285, 0.9714285714285714, 0.9928571428571429, 0.9785714285714285, 1.0, 0.9357142857142857, 0.9928571428571429, 0.9, 0.9857142857142858, 0.9785714285714285, 0.9714285714285714, 0.9714285714285714, 0.9928571428571429, 0.9857142857142858, 0.9785714285714285, 0.9714285714285714, 0.9857142857142858, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.316, 0.316, 0.316, 0.316, 0.122, 0.07, 0.162, 0.156, 0.122, 0.122, 0.316, 0.316, 0.316, 0.316, 0.316, 0.124, 0.138, 0.188, 0.176, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.33, 0.232, 0.232, 0.248, 0.272, 0.472, 0.446, 0.448, 0.478, 0.564, 0.45, 0.388, 0.434, 0.498, 0.536, 0.544, 0.542, 0.57, 0.694, 0.714, 0.71, 0.704, 0.71, 0.712, 0.716, 0.724, 0.722, 0.726, 0.732, 0.674, 0.728, 0.718, 0.662, 0.704, 0.742, 0.698, 0.73, 0.626, 0.724, 0.668, 0.73, 0.686, 0.664, 0.682, 0.716, 0.7, 0.676, 0.64, 0.692, 0.692, 0.704, 0.726, 0.71, 0.718, 0.718, 0.71, 0.706, 0.708, 0.714, 0.716, 0.72, 0.724, 0.724, 0.728, 0.732, 0.726, 0.724, 0.726, 0.734, 0.736, 0.742, 0.744, 0.742, 0.74, 0.738, 0.736, 0.736, 0.734, 0.734, 0.732, 0.732, 0.732, 0.732, 0.732, 0.732, 0.734, 0.736, 0.738, 0.748, 0.748, 0.75, 0.752, 0.752, 0.752, 0.748, 0.748, 0.748, 0.748, 0.748, 0.75, 0.75, 0.752, 0.75, 0.75, 0.748, 0.748, 0.748, 0.748, 0.748, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.748, 0.748, 0.748, 0.748, 0.748, 0.75, 0.75, 0.75, 0.75, 0.75, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.754, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.756, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752, 0.752]
test_accuracy_list: [0.319, 0.319, 0.319, 0.319, 0.13, 0.069, 0.149, 0.144, 0.13, 0.13, 0.319, 0.319, 0.319, 0.319, 0.318, 0.111, 0.128, 0.162, 0.164, 0.149, 0.149, 0.149, 0.149, 0.149, 0.156, 0.299, 0.215, 0.219, 0.242, 0.259, 0.475, 0.444, 0.451, 0.493, 0.561, 0.443, 0.401, 0.45, 0.495, 0.53, 0.537, 0.535, 0.571, 0.706, 0.725, 0.719, 0.725, 0.731, 0.728, 0.729, 0.727, 0.728, 0.731, 0.736, 0.664, 0.733, 0.703, 0.644, 0.692, 0.731, 0.71, 0.746, 0.578, 0.714, 0.649, 0.717, 0.66, 0.643, 0.674, 0.726, 0.712, 0.685, 0.652, 0.688, 0.705, 0.714, 0.722, 0.723, 0.72, 0.719, 0.715, 0.713, 0.708, 0.703, 0.708, 0.711, 0.719, 0.724, 0.723, 0.723, 0.722, 0.719, 0.721, 0.724, 0.725, 0.729, 0.729, 0.731, 0.731, 0.732, 0.731, 0.734, 0.735, 0.731, 0.731, 0.732, 0.734, 0.733, 0.735, 0.735, 0.734, 0.734, 0.736, 0.735, 0.734, 0.734, 0.733, 0.732, 0.733, 0.732, 0.731, 0.732, 0.733, 0.733, 0.732, 0.732, 0.732, 0.732, 0.734, 0.735, 0.735, 0.733, 0.733, 0.733, 0.732, 0.732, 0.732, 0.733, 0.733, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735, 0.736, 0.736, 0.736, 0.737, 0.737, 0.737, 0.738, 0.738, 0.738, 0.739, 0.739, 0.739, 0.738, 0.737, 0.737, 0.737, 0.737, 0.737, 0.737, 0.737, 0.737, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.738, 0.738, 0.738, 0.737, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738, 0.738, 0.739, 0.738, 0.738, 0.738, 0.738, 0.74, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741, 0.741, 0.742, 0.743, 0.743, 0.743, 0.744, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.747, 0.747, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.745, 0.745, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.746, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.747, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.748, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.749, 0.748, 0.748, 0.748]
best validation: 0.756
best test: 0.749
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 3
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 128
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.8043, Train: 58.57%, Valid: 35.20%, Test: 36.30%, Best Valid: 39.60%, Best Test: 38.90%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 66.80%, Test: 70.50%, Best Valid: 71.00%, Best Test: 74.10%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 70.70%, Best Valid: 71.00%, Best Test: 74.10%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 67.20%, Test: 70.80%, Best Valid: 71.00%, Best Test: 74.10%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 70.70%, Best Valid: 71.00%, Best Test: 74.10%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 67.60%, Test: 70.80%, Best Valid: 71.00%, Best Test: 74.10%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 67.40%, Test: 71.10%, Best Valid: 71.00%, Best Test: 74.10%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.18571428571428572, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.22142857142857142, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.15, 0.18571428571428572, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.22857142857142856, 0.16428571428571428, 0.18571428571428572, 0.37142857142857144, 0.55, 0.4714285714285714, 0.45, 0.39285714285714285, 0.35, 0.39285714285714285, 0.44285714285714284, 0.5857142857142857, 0.6857142857142857, 0.8142857142857143, 0.8428571428571429, 0.8285714285714286, 0.8357142857142857, 0.8285714285714286, 0.8214285714285714, 0.8214285714285714, 0.8214285714285714, 0.8285714285714286, 0.8428571428571429, 0.8714285714285714, 0.9142857142857143, 0.9214285714285714, 0.9214285714285714, 0.9428571428571428, 0.9571428571428572, 0.9642857142857143, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.122, 0.122, 0.14, 0.114, 0.058, 0.162, 0.122, 0.072, 0.114, 0.158, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.316, 0.316, 0.316, 0.316, 0.316, 0.316, 0.316, 0.122, 0.122, 0.122, 0.122, 0.122, 0.162, 0.164, 0.164, 0.122, 0.072, 0.072, 0.072, 0.072, 0.08, 0.304, 0.314, 0.316, 0.352, 0.396, 0.254, 0.21, 0.18, 0.172, 0.16, 0.194, 0.352, 0.5, 0.618, 0.668, 0.648, 0.632, 0.612, 0.602, 0.618, 0.626, 0.642, 0.676, 0.684, 0.702, 0.706, 0.694, 0.684, 0.688, 0.706, 0.704, 0.702, 0.706, 0.702, 0.71, 0.71, 0.704, 0.694, 0.682, 0.678, 0.674, 0.67, 0.674, 0.682, 0.68, 0.68, 0.678, 0.678, 0.672, 0.664, 0.658, 0.656, 0.658, 0.66, 0.662, 0.662, 0.662, 0.662, 0.664, 0.66, 0.66, 0.668, 0.672, 0.672, 0.672, 0.67, 0.668, 0.666, 0.664, 0.668, 0.668, 0.67, 0.672, 0.672, 0.674, 0.674, 0.676, 0.676, 0.672, 0.67, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.67, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.674, 0.674, 0.672, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.672, 0.672, 0.674, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672]
test_accuracy_list: [0.13, 0.13, 0.147, 0.103, 0.064, 0.149, 0.13, 0.091, 0.103, 0.151, 0.064, 0.064, 0.064, 0.064, 0.064, 0.064, 0.064, 0.32, 0.319, 0.319, 0.319, 0.319, 0.319, 0.319, 0.13, 0.13, 0.13, 0.13, 0.132, 0.15, 0.149, 0.149, 0.149, 0.091, 0.091, 0.091, 0.091, 0.095, 0.316, 0.319, 0.321, 0.377, 0.389, 0.242, 0.203, 0.195, 0.195, 0.196, 0.24, 0.363, 0.536, 0.65, 0.7, 0.693, 0.652, 0.628, 0.623, 0.637, 0.661, 0.692, 0.714, 0.734, 0.741, 0.721, 0.709, 0.709, 0.708, 0.714, 0.714, 0.714, 0.702, 0.705, 0.717, 0.723, 0.713, 0.705, 0.691, 0.685, 0.692, 0.703, 0.705, 0.706, 0.705, 0.704, 0.704, 0.705, 0.707, 0.709, 0.709, 0.71, 0.711, 0.71, 0.709, 0.708, 0.707, 0.706, 0.707, 0.707, 0.706, 0.705, 0.705, 0.707, 0.704, 0.704, 0.705, 0.706, 0.707, 0.706, 0.707, 0.706, 0.707, 0.708, 0.709, 0.708, 0.705, 0.705, 0.704, 0.703, 0.704, 0.704, 0.704, 0.704, 0.703, 0.703, 0.703, 0.702, 0.704, 0.704, 0.704, 0.704, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.705, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.708, 0.708, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.709, 0.709, 0.709, 0.709, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.713]
best validation: 0.71
best test: 0.741
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 4
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 256
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.6485, Train: 50.00%, Valid: 38.60%, Test: 39.00%, Best Valid: 38.60%, Best Test: 39.00%
Epoch: 100, Loss: 0.0003, Train: 100.00%, Valid: 67.80%, Test: 66.30%, Best Valid: 68.20%, Best Test: 67.00%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 67.60%, Test: 65.80%, Best Valid: 68.20%, Best Test: 67.00%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 65.90%, Best Valid: 68.20%, Best Test: 67.00%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 66.00%, Best Valid: 68.20%, Best Test: 67.00%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 65.90%, Best Valid: 68.40%, Best Test: 67.00%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 66.00%, Best Valid: 68.80%, Best Test: 67.00%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.2, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.19285714285714287, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.1357142857142857, 0.15714285714285714, 0.15714285714285714, 0.15, 0.15, 0.15, 0.15714285714285714, 0.22857142857142856, 0.21428571428571427, 0.3142857142857143, 0.3142857142857143, 0.2857142857142857, 0.3, 0.3142857142857143, 0.3142857142857143, 0.35, 0.37857142857142856, 0.4857142857142857, 0.4642857142857143, 0.4642857142857143, 0.5071428571428571, 0.5, 0.5, 0.4714285714285714, 0.4642857142857143, 0.5071428571428571, 0.5928571428571429, 0.7642857142857142, 0.8571428571428571, 0.8428571428571429, 0.8571428571428571, 0.8857142857142857, 0.8857142857142857, 0.9142857142857143, 0.8857142857142857, 0.9285714285714286, 0.9428571428571428, 0.9142857142857143, 0.9571428571428572, 0.9642857142857143, 0.9785714285714285, 0.9571428571428572, 0.9857142857142858, 0.9785714285714285, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.122, 0.122, 0.122, 0.058, 0.072, 0.316, 0.122, 0.164, 0.22, 0.156, 0.156, 0.156, 0.156, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.116, 0.116, 0.072, 0.072, 0.072, 0.072, 0.072, 0.074, 0.078, 0.132, 0.126, 0.124, 0.124, 0.124, 0.178, 0.184, 0.214, 0.116, 0.112, 0.112, 0.114, 0.126, 0.15, 0.182, 0.31, 0.264, 0.28, 0.34, 0.386, 0.396, 0.398, 0.416, 0.46, 0.502, 0.594, 0.582, 0.558, 0.532, 0.572, 0.612, 0.588, 0.626, 0.576, 0.558, 0.65, 0.646, 0.628, 0.63, 0.638, 0.658, 0.642, 0.666, 0.672, 0.656, 0.652, 0.67, 0.678, 0.678, 0.682, 0.678, 0.682, 0.67, 0.67, 0.666, 0.666, 0.668, 0.67, 0.678, 0.682, 0.678, 0.676, 0.674, 0.67, 0.672, 0.672, 0.674, 0.674, 0.674, 0.678, 0.676, 0.674, 0.674, 0.676, 0.674, 0.672, 0.672, 0.674, 0.674, 0.674, 0.676, 0.672, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.68, 0.68, 0.68, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688]
test_accuracy_list: [0.13, 0.13, 0.13, 0.064, 0.091, 0.319, 0.13, 0.151, 0.171, 0.146, 0.144, 0.144, 0.144, 0.064, 0.064, 0.064, 0.064, 0.064, 0.064, 0.064, 0.064, 0.105, 0.104, 0.091, 0.091, 0.091, 0.091, 0.093, 0.093, 0.098, 0.132, 0.13, 0.131, 0.131, 0.139, 0.167, 0.162, 0.185, 0.125, 0.119, 0.12, 0.124, 0.13, 0.148, 0.189, 0.312, 0.28, 0.279, 0.349, 0.39, 0.41, 0.412, 0.419, 0.436, 0.498, 0.59, 0.604, 0.55, 0.52, 0.568, 0.618, 0.586, 0.616, 0.559, 0.547, 0.632, 0.645, 0.607, 0.615, 0.616, 0.647, 0.631, 0.652, 0.659, 0.627, 0.617, 0.641, 0.661, 0.663, 0.663, 0.66, 0.65, 0.645, 0.635, 0.63, 0.631, 0.637, 0.643, 0.649, 0.654, 0.656, 0.665, 0.668, 0.67, 0.669, 0.67, 0.67, 0.667, 0.666, 0.663, 0.662, 0.656, 0.658, 0.657, 0.657, 0.659, 0.656, 0.654, 0.654, 0.653, 0.655, 0.657, 0.657, 0.655, 0.655, 0.656, 0.659, 0.659, 0.658, 0.658, 0.66, 0.66, 0.66, 0.661, 0.661, 0.662, 0.662, 0.663, 0.661, 0.662, 0.661, 0.66, 0.659, 0.659, 0.659, 0.658, 0.657, 0.656, 0.657, 0.656, 0.657, 0.658, 0.657, 0.657, 0.657, 0.657, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.659, 0.661, 0.661, 0.662, 0.662, 0.662, 0.662, 0.662, 0.661, 0.661, 0.661, 0.661, 0.66, 0.66, 0.659, 0.659, 0.658, 0.658, 0.658, 0.658, 0.658, 0.658, 0.659, 0.659, 0.659, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.66, 0.66, 0.66, 0.661, 0.661, 0.661, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.659, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.661, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.663, 0.663, 0.663]
best validation: 0.688
best test: 0.67
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 4
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 256
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.5631, Train: 90.71%, Valid: 65.00%, Test: 70.00%, Best Valid: 65.00%, Best Test: 70.00%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 69.50%, Best Valid: 68.40%, Best Test: 71.00%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 70.00%, Best Valid: 69.00%, Best Test: 71.00%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 70.70%, Best Valid: 69.00%, Best Test: 71.00%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 67.60%, Test: 70.70%, Best Valid: 69.00%, Best Test: 71.00%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 67.60%, Test: 70.60%, Best Valid: 69.00%, Best Test: 71.00%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 70.70%, Best Valid: 69.00%, Best Test: 71.00%
train_accuracy_list: [0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.20714285714285716, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15, 0.16428571428571428, 0.15, 0.14285714285714285, 0.14285714285714285, 0.15, 0.16428571428571428, 0.22142857142857142, 0.15, 0.17142857142857143, 0.2, 0.25, 0.32142857142857145, 0.4357142857142857, 0.4857142857142857, 0.4928571428571429, 0.5, 0.5142857142857142, 0.5428571428571428, 0.4928571428571429, 0.5285714285714286, 0.5571428571428572, 0.5785714285714286, 0.6571428571428571, 0.7214285714285714, 0.7785714285714286, 0.8071428571428572, 0.8428571428571429, 0.8857142857142857, 0.9071428571428571, 0.9214285714285714, 0.95, 0.9642857142857143, 0.9642857142857143, 0.9642857142857143, 0.9571428571428572, 0.9857142857142858, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.128, 0.072, 0.072, 0.162, 0.156, 0.122, 0.072, 0.072, 0.072, 0.058, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.164, 0.31, 0.316, 0.158, 0.156, 0.156, 0.156, 0.164, 0.2, 0.122, 0.122, 0.124, 0.126, 0.156, 0.254, 0.402, 0.384, 0.394, 0.424, 0.458, 0.48, 0.482, 0.566, 0.588, 0.59, 0.628, 0.628, 0.634, 0.636, 0.632, 0.65, 0.658, 0.66, 0.656, 0.66, 0.662, 0.644, 0.656, 0.664, 0.658, 0.668, 0.672, 0.674, 0.668, 0.672, 0.674, 0.664, 0.68, 0.682, 0.684, 0.676, 0.678, 0.672, 0.666, 0.672, 0.672, 0.668, 0.666, 0.666, 0.668, 0.67, 0.67, 0.674, 0.674, 0.674, 0.676, 0.678, 0.678, 0.678, 0.674, 0.678, 0.676, 0.678, 0.674, 0.676, 0.674, 0.67, 0.672, 0.672, 0.678, 0.678, 0.68, 0.686, 0.686, 0.686, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.686, 0.684, 0.684, 0.682, 0.678, 0.678, 0.678, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.672, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.68, 0.68, 0.68, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.678, 0.678, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68]
test_accuracy_list: [0.128, 0.091, 0.091, 0.149, 0.144, 0.13, 0.091, 0.091, 0.1, 0.064, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.32, 0.327, 0.144, 0.144, 0.144, 0.145, 0.146, 0.187, 0.13, 0.132, 0.136, 0.144, 0.155, 0.278, 0.404, 0.384, 0.397, 0.423, 0.454, 0.48, 0.504, 0.562, 0.58, 0.588, 0.623, 0.633, 0.653, 0.676, 0.676, 0.7, 0.705, 0.686, 0.673, 0.678, 0.691, 0.653, 0.68, 0.674, 0.66, 0.67, 0.696, 0.704, 0.706, 0.696, 0.683, 0.678, 0.682, 0.698, 0.707, 0.709, 0.71, 0.709, 0.707, 0.703, 0.695, 0.689, 0.685, 0.681, 0.681, 0.68, 0.677, 0.678, 0.678, 0.681, 0.684, 0.684, 0.685, 0.693, 0.694, 0.696, 0.695, 0.699, 0.7, 0.698, 0.695, 0.693, 0.695, 0.696, 0.696, 0.695, 0.697, 0.696, 0.701, 0.701, 0.703, 0.703, 0.703, 0.706, 0.705, 0.707, 0.704, 0.704, 0.701, 0.699, 0.698, 0.698, 0.698, 0.698, 0.696, 0.696, 0.695, 0.696, 0.697, 0.697, 0.697, 0.697, 0.698, 0.698, 0.698, 0.699, 0.699, 0.699, 0.699, 0.698, 0.698, 0.699, 0.698, 0.697, 0.697, 0.698, 0.698, 0.698, 0.699, 0.699, 0.699, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.701, 0.701, 0.702, 0.702, 0.702, 0.702, 0.703, 0.703, 0.703, 0.703, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.705, 0.705, 0.705, 0.705, 0.705, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.708, 0.708, 0.708, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.705, 0.705, 0.705, 0.705, 0.705, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.705, 0.705, 0.705, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.705, 0.705, 0.705, 0.705, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707]
best validation: 0.69
best test: 0.71
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 4
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 256
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.1387, Train: 65.00%, Valid: 52.80%, Test: 54.30%, Best Valid: 52.80%, Best Test: 54.30%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 68.60%, Test: 70.50%, Best Valid: 70.20%, Best Test: 72.60%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 69.40%, Test: 71.30%, Best Valid: 70.20%, Best Test: 72.60%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 69.80%, Test: 71.80%, Best Valid: 70.20%, Best Test: 72.60%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 69.40%, Test: 71.40%, Best Valid: 70.20%, Best Test: 72.60%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 69.60%, Test: 71.10%, Best Valid: 70.20%, Best Test: 72.60%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 69.80%, Test: 71.10%, Best Valid: 70.20%, Best Test: 72.60%
train_accuracy_list: [0.14285714285714285, 0.22142857142857142, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.15, 0.15, 0.15714285714285714, 0.19285714285714287, 0.17857142857142858, 0.18571428571428572, 0.25, 0.2571428571428571, 0.21428571428571427, 0.17142857142857143, 0.2, 0.32142857142857145, 0.4, 0.3357142857142857, 0.29285714285714287, 0.3, 0.3142857142857143, 0.37857142857142856, 0.45714285714285713, 0.4714285714285714, 0.5142857142857142, 0.5857142857142857, 0.6071428571428571, 0.6142857142857143, 0.6285714285714286, 0.65, 0.7928571428571428, 0.8642857142857143, 0.8071428571428572, 0.7428571428571429, 0.7571428571428571, 0.9, 0.9357142857142857, 0.9142857142857143, 0.9642857142857143, 0.9857142857142858, 0.9714285714285714, 0.9928571428571429, 0.9785714285714285, 0.9857142857142858, 1.0, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.116, 0.116, 0.072, 0.122, 0.156, 0.316, 0.072, 0.162, 0.162, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.114, 0.15, 0.156, 0.158, 0.158, 0.16, 0.164, 0.31, 0.304, 0.314, 0.136, 0.084, 0.066, 0.08, 0.092, 0.158, 0.14, 0.154, 0.162, 0.17, 0.186, 0.238, 0.274, 0.346, 0.376, 0.416, 0.452, 0.492, 0.528, 0.566, 0.612, 0.492, 0.44, 0.448, 0.568, 0.624, 0.62, 0.654, 0.664, 0.672, 0.654, 0.688, 0.676, 0.67, 0.672, 0.686, 0.702, 0.69, 0.696, 0.694, 0.684, 0.684, 0.696, 0.69, 0.69, 0.694, 0.692, 0.686, 0.69, 0.688, 0.692, 0.682, 0.684, 0.682, 0.69, 0.692, 0.692, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.688, 0.686, 0.686, 0.684, 0.68, 0.68, 0.682, 0.682, 0.684, 0.686, 0.688, 0.684, 0.686, 0.686, 0.688, 0.69, 0.692, 0.69, 0.688, 0.688, 0.69, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.694, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.694, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.696, 0.696, 0.696, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698]
test_accuracy_list: [0.103, 0.101, 0.091, 0.13, 0.144, 0.319, 0.091, 0.149, 0.149, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.105, 0.152, 0.145, 0.145, 0.148, 0.148, 0.159, 0.327, 0.326, 0.333, 0.165, 0.105, 0.075, 0.096, 0.142, 0.16, 0.145, 0.149, 0.163, 0.17, 0.189, 0.219, 0.259, 0.315, 0.379, 0.447, 0.501, 0.517, 0.543, 0.594, 0.623, 0.519, 0.445, 0.453, 0.573, 0.638, 0.633, 0.668, 0.7, 0.682, 0.666, 0.696, 0.69, 0.693, 0.696, 0.711, 0.724, 0.726, 0.712, 0.711, 0.707, 0.717, 0.716, 0.718, 0.718, 0.711, 0.71, 0.706, 0.701, 0.701, 0.701, 0.705, 0.706, 0.704, 0.704, 0.705, 0.703, 0.703, 0.701, 0.701, 0.7, 0.701, 0.699, 0.7, 0.7, 0.704, 0.702, 0.703, 0.705, 0.705, 0.703, 0.703, 0.702, 0.703, 0.704, 0.706, 0.706, 0.707, 0.708, 0.707, 0.707, 0.707, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.707, 0.708, 0.708, 0.709, 0.71, 0.709, 0.709, 0.708, 0.709, 0.709, 0.708, 0.708, 0.708, 0.709, 0.71, 0.71, 0.71, 0.71, 0.71, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.712, 0.712, 0.713, 0.712, 0.712, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.715, 0.715, 0.714, 0.715, 0.715, 0.716, 0.716, 0.717, 0.717, 0.717, 0.717, 0.717, 0.716, 0.716, 0.716, 0.716, 0.717, 0.717, 0.717, 0.717, 0.718, 0.717, 0.717, 0.717, 0.718, 0.718, 0.718, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.717, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.712, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711, 0.711]
best validation: 0.702
best test: 0.726
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 5
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 512
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.6587, Train: 80.71%, Valid: 52.20%, Test: 52.30%, Best Valid: 52.20%, Best Test: 52.30%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.20%, Test: 62.40%, Best Valid: 65.40%, Best Test: 63.40%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 65.00%, Test: 62.40%, Best Valid: 65.60%, Best Test: 63.40%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 64.80%, Test: 62.40%, Best Valid: 65.60%, Best Test: 63.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 64.80%, Test: 62.30%, Best Valid: 65.60%, Best Test: 63.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 64.80%, Test: 62.50%, Best Valid: 65.60%, Best Test: 63.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 64.60%, Test: 62.50%, Best Valid: 65.60%, Best Test: 63.40%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17142857142857143, 0.19285714285714287, 0.19285714285714287, 0.2, 0.21428571428571427, 0.18571428571428572, 0.20714285714285716, 0.2714285714285714, 0.29285714285714287, 0.2857142857142857, 0.29285714285714287, 0.3, 0.3142857142857143, 0.34285714285714286, 0.36428571428571427, 0.37857142857142856, 0.42857142857142855, 0.45, 0.5428571428571428, 0.55, 0.6, 0.6428571428571429, 0.5857142857142857, 0.6142857142857143, 0.7, 0.75, 0.7642857142857142, 0.7928571428571428, 0.8071428571428572, 0.9071428571428571, 0.9, 0.9428571428571428, 0.9428571428571428, 0.9785714285714285, 1.0, 1.0, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.058, 0.058, 0.316, 0.072, 0.114, 0.058, 0.122, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.156, 0.156, 0.316, 0.314, 0.222, 0.058, 0.058, 0.058, 0.078, 0.106, 0.11, 0.12, 0.14, 0.144, 0.152, 0.14, 0.15, 0.214, 0.258, 0.268, 0.26, 0.268, 0.298, 0.31, 0.37, 0.37, 0.372, 0.44, 0.436, 0.444, 0.384, 0.398, 0.496, 0.504, 0.428, 0.464, 0.522, 0.562, 0.506, 0.522, 0.588, 0.592, 0.588, 0.592, 0.61, 0.584, 0.63, 0.624, 0.608, 0.61, 0.622, 0.626, 0.63, 0.63, 0.624, 0.626, 0.634, 0.636, 0.65, 0.652, 0.654, 0.652, 0.648, 0.644, 0.648, 0.644, 0.642, 0.64, 0.642, 0.64, 0.644, 0.644, 0.642, 0.64, 0.642, 0.642, 0.644, 0.644, 0.644, 0.644, 0.644, 0.646, 0.65, 0.65, 0.65, 0.652, 0.652, 0.652, 0.656, 0.654, 0.652, 0.65, 0.65, 0.652, 0.652, 0.652, 0.652, 0.652, 0.65, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.65, 0.65, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646]
test_accuracy_list: [0.064, 0.064, 0.319, 0.091, 0.103, 0.064, 0.13, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.144, 0.144, 0.318, 0.318, 0.236, 0.064, 0.064, 0.064, 0.083, 0.097, 0.1, 0.113, 0.141, 0.165, 0.17, 0.165, 0.178, 0.226, 0.228, 0.246, 0.266, 0.296, 0.308, 0.332, 0.366, 0.366, 0.354, 0.459, 0.398, 0.474, 0.426, 0.42, 0.489, 0.492, 0.421, 0.471, 0.523, 0.545, 0.488, 0.534, 0.535, 0.57, 0.558, 0.558, 0.575, 0.549, 0.591, 0.596, 0.575, 0.574, 0.598, 0.611, 0.61, 0.599, 0.59, 0.601, 0.618, 0.625, 0.628, 0.63, 0.634, 0.633, 0.629, 0.625, 0.624, 0.624, 0.625, 0.625, 0.625, 0.625, 0.623, 0.622, 0.624, 0.623, 0.623, 0.623, 0.624, 0.623, 0.624, 0.623, 0.625, 0.625, 0.624, 0.625, 0.625, 0.625, 0.624, 0.624, 0.624, 0.624, 0.625, 0.625, 0.624, 0.625, 0.625, 0.623, 0.622, 0.622, 0.621, 0.622, 0.622, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.624, 0.624, 0.624, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.623, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.623, 0.623, 0.623, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.623, 0.623, 0.623, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625]
best validation: 0.656
best test: 0.634
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 5
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 512
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 1.1946, Train: 58.57%, Valid: 39.60%, Test: 39.90%, Best Valid: 40.20%, Best Test: 39.90%
Epoch: 100, Loss: 0.0162, Train: 100.00%, Valid: 65.00%, Test: 67.60%, Best Valid: 65.00%, Best Test: 68.40%
Epoch: 150, Loss: 0.0005, Train: 100.00%, Valid: 68.00%, Test: 71.10%, Best Valid: 68.00%, Best Test: 71.10%
Epoch: 200, Loss: 0.0001, Train: 100.00%, Valid: 67.60%, Test: 71.40%, Best Valid: 68.60%, Best Test: 71.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 70.70%, Best Valid: 68.60%, Best Test: 71.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 70.70%, Best Valid: 68.60%, Best Test: 71.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 70.70%, Best Valid: 68.60%, Best Test: 71.40%
train_accuracy_list: [0.15714285714285714, 0.14285714285714285, 0.15714285714285714, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.21428571428571427, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.15, 0.14285714285714285, 0.1357142857142857, 0.15714285714285714, 0.14285714285714285, 0.2357142857142857, 0.15, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.15, 0.22142857142857142, 0.22142857142857142, 0.20714285714285716, 0.29285714285714287, 0.3, 0.2714285714285714, 0.29285714285714287, 0.32857142857142857, 0.3, 0.2857142857142857, 0.3142857142857143, 0.3142857142857143, 0.37857142857142856, 0.4642857142857143, 0.5285714285714286, 0.5571428571428572, 0.5857142857142857, 0.6071428571428571, 0.6785714285714286, 0.7285714285714285, 0.7071428571428572, 0.7357142857142858, 0.7285714285714285, 0.7142857142857143, 0.7071428571428572, 0.6928571428571428, 0.6928571428571428, 0.8428571428571429, 0.8285714285714286, 0.85, 0.85, 0.8857142857142857, 0.9, 0.9214285714285714, 0.9285714285714286, 0.8357142857142857, 0.5785714285714286, 0.8071428571428572, 0.7357142857142858, 0.8428571428571429, 0.7357142857142858, 0.9785714285714285, 0.8642857142857143, 0.8928571428571429, 0.9285714285714286, 0.95, 0.9571428571428572, 0.9357142857142857, 0.95, 0.9857142857142858, 0.9857142857142858, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.316, 0.162, 0.12, 0.156, 0.316, 0.162, 0.098, 0.058, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.114, 0.162, 0.162, 0.162, 0.17, 0.316, 0.312, 0.186, 0.08, 0.122, 0.122, 0.138, 0.066, 0.158, 0.156, 0.156, 0.17, 0.2, 0.16, 0.146, 0.214, 0.238, 0.228, 0.252, 0.26, 0.262, 0.27, 0.306, 0.346, 0.366, 0.348, 0.366, 0.402, 0.396, 0.43, 0.414, 0.524, 0.528, 0.508, 0.508, 0.484, 0.41, 0.47, 0.51, 0.514, 0.566, 0.584, 0.548, 0.534, 0.58, 0.618, 0.598, 0.476, 0.51, 0.484, 0.368, 0.48, 0.514, 0.61, 0.55, 0.582, 0.608, 0.634, 0.564, 0.502, 0.51, 0.578, 0.584, 0.574, 0.574, 0.588, 0.59, 0.604, 0.62, 0.64, 0.644, 0.65, 0.648, 0.646, 0.644, 0.646, 0.644, 0.648, 0.65, 0.652, 0.656, 0.662, 0.66, 0.662, 0.662, 0.662, 0.658, 0.658, 0.656, 0.658, 0.654, 0.658, 0.658, 0.66, 0.662, 0.662, 0.664, 0.666, 0.668, 0.67, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.666, 0.664, 0.662, 0.66, 0.658, 0.658, 0.658, 0.658, 0.658, 0.66, 0.66, 0.66, 0.664, 0.668, 0.672, 0.674, 0.674, 0.672, 0.678, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.684, 0.686, 0.686, 0.686, 0.684, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682, 0.682, 0.684, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.684, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.676, 0.676, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.674, 0.674, 0.676, 0.676, 0.676, 0.674, 0.674, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.674, 0.674, 0.674, 0.672, 0.672, 0.67, 0.672, 0.666, 0.664, 0.668, 0.67, 0.666, 0.656, 0.656, 0.66, 0.666, 0.67, 0.666, 0.66, 0.668, 0.672, 0.666, 0.662, 0.66, 0.662, 0.658, 0.662, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.668, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.666, 0.666, 0.664, 0.664, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668]
test_accuracy_list: [0.324, 0.149, 0.105, 0.144, 0.319, 0.149, 0.113, 0.064, 0.103, 0.103, 0.103, 0.103, 0.103, 0.103, 0.103, 0.103, 0.103, 0.149, 0.149, 0.149, 0.149, 0.319, 0.313, 0.187, 0.113, 0.144, 0.131, 0.15, 0.071, 0.142, 0.144, 0.144, 0.147, 0.17, 0.134, 0.126, 0.177, 0.203, 0.182, 0.213, 0.232, 0.246, 0.24, 0.296, 0.355, 0.355, 0.336, 0.355, 0.385, 0.399, 0.424, 0.434, 0.5, 0.504, 0.5, 0.495, 0.494, 0.429, 0.458, 0.492, 0.521, 0.56, 0.556, 0.537, 0.548, 0.576, 0.598, 0.586, 0.52, 0.467, 0.495, 0.423, 0.51, 0.521, 0.621, 0.58, 0.601, 0.625, 0.641, 0.591, 0.528, 0.561, 0.607, 0.64, 0.62, 0.609, 0.614, 0.623, 0.642, 0.647, 0.66, 0.676, 0.684, 0.682, 0.675, 0.664, 0.66, 0.666, 0.669, 0.676, 0.683, 0.683, 0.691, 0.693, 0.695, 0.694, 0.691, 0.69, 0.684, 0.685, 0.684, 0.686, 0.687, 0.688, 0.691, 0.694, 0.696, 0.701, 0.703, 0.704, 0.706, 0.709, 0.709, 0.709, 0.708, 0.705, 0.703, 0.701, 0.699, 0.698, 0.699, 0.699, 0.698, 0.697, 0.697, 0.699, 0.699, 0.7, 0.7, 0.703, 0.704, 0.704, 0.704, 0.706, 0.706, 0.706, 0.707, 0.709, 0.71, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.709, 0.709, 0.709, 0.71, 0.71, 0.71, 0.71, 0.71, 0.709, 0.709, 0.709, 0.709, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.712, 0.713, 0.713, 0.713, 0.712, 0.712, 0.714, 0.712, 0.712, 0.712, 0.711, 0.711, 0.711, 0.711, 0.71, 0.711, 0.71, 0.71, 0.705, 0.705, 0.705, 0.704, 0.701, 0.7, 0.7, 0.7, 0.7, 0.7, 0.697, 0.699, 0.7, 0.702, 0.702, 0.701, 0.699, 0.701, 0.699, 0.702, 0.7, 0.7, 0.704, 0.707, 0.706, 0.704, 0.702, 0.702, 0.7, 0.699, 0.7, 0.701, 0.7, 0.699, 0.703, 0.701, 0.703, 0.706, 0.707, 0.706, 0.704, 0.705, 0.706, 0.707, 0.706, 0.703, 0.703, 0.703, 0.703, 0.702, 0.701, 0.702, 0.703, 0.701, 0.699, 0.7, 0.7, 0.701, 0.701, 0.701, 0.703, 0.703, 0.703, 0.703, 0.704, 0.705, 0.705, 0.706, 0.706, 0.706, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.707, 0.707, 0.708, 0.707, 0.707, 0.707, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.705, 0.705, 0.705]
best validation: 0.686
best test: 0.714
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 5
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 512
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.1493, Train: 97.14%, Valid: 71.80%, Test: 71.10%, Best Valid: 72.20%, Best Test: 71.60%
Epoch: 100, Loss: 0.0023, Train: 100.00%, Valid: 68.40%, Test: 71.30%, Best Valid: 74.00%, Best Test: 74.70%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 70.40%, Test: 71.80%, Best Valid: 74.00%, Best Test: 74.70%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 70.80%, Test: 72.30%, Best Valid: 74.00%, Best Test: 74.70%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 70.00%, Test: 71.60%, Best Valid: 74.00%, Best Test: 74.70%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 69.40%, Test: 71.10%, Best Valid: 74.00%, Best Test: 74.70%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 69.40%, Test: 70.80%, Best Valid: 74.00%, Best Test: 74.70%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.12857142857142856, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15, 0.15, 0.24285714285714285, 0.17142857142857143, 0.17857142857142858, 0.25, 0.2714285714285714, 0.3142857142857143, 0.2357142857142857, 0.2571428571428571, 0.32142857142857145, 0.36428571428571427, 0.30714285714285716, 0.29285714285714287, 0.3357142857142857, 0.4928571428571429, 0.5785714285714286, 0.6071428571428571, 0.6857142857142857, 0.7642857142857142, 0.7571428571428571, 0.8357142857142857, 0.8571428571428571, 0.8928571428571429, 0.9, 0.9428571428571428, 0.9714285714285714, 0.9642857142857143, 0.9714285714285714, 0.9714285714285714, 0.9857142857142858, 0.9785714285714285, 0.9642857142857143, 0.9857142857142858, 0.9571428571428572, 0.9857142857142858, 0.9, 0.9857142857142858, 0.7714285714285715, 0.9857142857142858, 0.7785714285714286, 0.8214285714285714, 0.9928571428571429, 0.9214285714285714, 0.95, 0.9642857142857143, 0.95, 0.9071428571428571, 0.9714285714285714, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.156, 0.058, 0.122, 0.114, 0.058, 0.162, 0.162, 0.122, 0.122, 0.122, 0.122, 0.122, 0.122, 0.126, 0.122, 0.124, 0.122, 0.072, 0.072, 0.072, 0.072, 0.072, 0.078, 0.062, 0.064, 0.132, 0.166, 0.24, 0.226, 0.23, 0.244, 0.232, 0.192, 0.174, 0.204, 0.312, 0.458, 0.462, 0.508, 0.502, 0.478, 0.6, 0.636, 0.646, 0.672, 0.67, 0.708, 0.722, 0.698, 0.718, 0.74, 0.698, 0.702, 0.722, 0.616, 0.69, 0.562, 0.694, 0.48, 0.678, 0.446, 0.464, 0.676, 0.69, 0.654, 0.636, 0.614, 0.586, 0.626, 0.686, 0.706, 0.722, 0.726, 0.732, 0.73, 0.716, 0.704, 0.706, 0.702, 0.702, 0.72, 0.716, 0.724, 0.718, 0.72, 0.714, 0.712, 0.706, 0.704, 0.694, 0.692, 0.686, 0.688, 0.684, 0.684, 0.688, 0.686, 0.684, 0.682, 0.684, 0.688, 0.688, 0.69, 0.692, 0.698, 0.698, 0.696, 0.698, 0.7, 0.7, 0.706, 0.702, 0.7, 0.698, 0.698, 0.7, 0.698, 0.698, 0.698, 0.7, 0.7, 0.702, 0.704, 0.704, 0.702, 0.706, 0.708, 0.704, 0.704, 0.702, 0.702, 0.704, 0.702, 0.7, 0.7, 0.7, 0.698, 0.698, 0.698, 0.7, 0.7, 0.7, 0.7, 0.704, 0.706, 0.706, 0.706, 0.704, 0.704, 0.704, 0.704, 0.702, 0.704, 0.704, 0.704, 0.704, 0.704, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.704, 0.704, 0.704, 0.704, 0.704, 0.706, 0.706, 0.706, 0.706, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.704, 0.706, 0.706, 0.706, 0.704, 0.704, 0.704, 0.704, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.702, 0.7, 0.7, 0.7, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.696, 0.696, 0.696, 0.696, 0.698, 0.698, 0.698, 0.698, 0.698, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.696, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688]
test_accuracy_list: [0.144, 0.064, 0.13, 0.103, 0.064, 0.149, 0.149, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.136, 0.13, 0.13, 0.127, 0.091, 0.091, 0.091, 0.092, 0.094, 0.091, 0.073, 0.076, 0.127, 0.156, 0.216, 0.195, 0.195, 0.222, 0.215, 0.194, 0.175, 0.221, 0.336, 0.492, 0.47, 0.516, 0.523, 0.52, 0.603, 0.637, 0.656, 0.68, 0.694, 0.714, 0.716, 0.71, 0.711, 0.741, 0.716, 0.7, 0.736, 0.64, 0.699, 0.584, 0.719, 0.481, 0.681, 0.459, 0.491, 0.677, 0.718, 0.693, 0.673, 0.647, 0.613, 0.663, 0.712, 0.73, 0.739, 0.743, 0.74, 0.745, 0.732, 0.725, 0.727, 0.735, 0.739, 0.745, 0.744, 0.742, 0.741, 0.747, 0.741, 0.739, 0.737, 0.734, 0.728, 0.721, 0.714, 0.706, 0.703, 0.704, 0.706, 0.705, 0.71, 0.711, 0.713, 0.717, 0.725, 0.726, 0.728, 0.726, 0.728, 0.728, 0.73, 0.732, 0.732, 0.73, 0.729, 0.73, 0.73, 0.728, 0.729, 0.73, 0.729, 0.726, 0.729, 0.724, 0.72, 0.72, 0.72, 0.717, 0.724, 0.724, 0.723, 0.72, 0.72, 0.719, 0.719, 0.719, 0.719, 0.72, 0.719, 0.719, 0.72, 0.719, 0.719, 0.719, 0.718, 0.717, 0.717, 0.716, 0.716, 0.717, 0.718, 0.718, 0.718, 0.72, 0.721, 0.723, 0.723, 0.724, 0.727, 0.727, 0.728, 0.728, 0.728, 0.727, 0.726, 0.726, 0.725, 0.726, 0.726, 0.726, 0.725, 0.725, 0.725, 0.725, 0.724, 0.722, 0.721, 0.721, 0.72, 0.72, 0.722, 0.722, 0.722, 0.722, 0.723, 0.723, 0.722, 0.723, 0.723, 0.723, 0.722, 0.722, 0.722, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.722, 0.722, 0.722, 0.722, 0.722, 0.721, 0.72, 0.72, 0.719, 0.718, 0.718, 0.718, 0.717, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.715, 0.715, 0.715, 0.715, 0.716, 0.716, 0.716, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.716, 0.716, 0.716, 0.716, 0.716, 0.716, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.715, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.714, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.713, 0.712, 0.712, 0.712, 0.712, 0.712, 0.711, 0.711, 0.711, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.709, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.708, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.707, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706, 0.706]
best validation: 0.74
best test: 0.747
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 6
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 1024
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.8055, Train: 83.57%, Valid: 49.60%, Test: 51.10%, Best Valid: 49.60%, Best Test: 51.10%
Epoch: 100, Loss: 0.0002, Train: 100.00%, Valid: 66.20%, Test: 68.30%, Best Valid: 66.20%, Best Test: 69.20%
Epoch: 150, Loss: 0.0001, Train: 100.00%, Valid: 66.20%, Test: 68.10%, Best Valid: 66.60%, Best Test: 69.20%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 67.30%, Best Valid: 66.80%, Best Test: 69.20%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 67.20%, Test: 67.40%, Best Valid: 67.20%, Best Test: 69.20%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 67.20%, Best Valid: 67.20%, Best Test: 69.20%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 67.20%, Best Valid: 67.20%, Best Test: 69.20%
train_accuracy_list: [0.17142857142857143, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17142857142857143, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15714285714285714, 0.20714285714285716, 0.16428571428571428, 0.18571428571428572, 0.2, 0.20714285714285716, 0.2714285714285714, 0.19285714285714287, 0.2785714285714286, 0.2714285714285714, 0.29285714285714287, 0.2714285714285714, 0.36428571428571427, 0.35, 0.34285714285714286, 0.36428571428571427, 0.4357142857142857, 0.4642857142857143, 0.5928571428571429, 0.5642857142857143, 0.5642857142857143, 0.7071428571428572, 0.6857142857142857, 0.6214285714285714, 0.7285714285714285, 0.7142857142857143, 0.6785714285714286, 0.7714285714285715, 0.5857142857142857, 0.8357142857142857, 0.7142857142857143, 0.8428571428571429, 0.7214285714285714, 0.8642857142857143, 0.8214285714285714, 0.8785714285714286, 0.9357142857142857, 0.8142857142857143, 0.9642857142857143, 0.9285714285714286, 0.9428571428571428, 0.9642857142857143, 0.9642857142857143, 0.9857142857142858, 0.9857142857142858, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.076, 0.072, 0.162, 0.058, 0.156, 0.072, 0.072, 0.078, 0.122, 0.122, 0.122, 0.122, 0.122, 0.314, 0.314, 0.308, 0.186, 0.156, 0.156, 0.156, 0.188, 0.2, 0.086, 0.076, 0.082, 0.092, 0.204, 0.184, 0.22, 0.248, 0.318, 0.302, 0.382, 0.366, 0.364, 0.366, 0.352, 0.252, 0.29, 0.262, 0.314, 0.418, 0.408, 0.422, 0.412, 0.472, 0.406, 0.44, 0.386, 0.496, 0.402, 0.474, 0.412, 0.542, 0.524, 0.474, 0.516, 0.514, 0.576, 0.584, 0.596, 0.632, 0.65, 0.654, 0.662, 0.64, 0.624, 0.626, 0.636, 0.638, 0.644, 0.648, 0.644, 0.642, 0.64, 0.636, 0.646, 0.652, 0.648, 0.652, 0.654, 0.656, 0.656, 0.656, 0.656, 0.654, 0.652, 0.652, 0.652, 0.652, 0.654, 0.658, 0.658, 0.658, 0.658, 0.656, 0.658, 0.658, 0.66, 0.662, 0.662, 0.662, 0.66, 0.658, 0.66, 0.66, 0.662, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.664, 0.662, 0.662, 0.662, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.662, 0.664, 0.662, 0.662, 0.662, 0.662, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.668, 0.668, 0.668, 0.668, 0.668, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668]
test_accuracy_list: [0.096, 0.091, 0.149, 0.064, 0.144, 0.091, 0.091, 0.097, 0.13, 0.13, 0.13, 0.13, 0.131, 0.319, 0.32, 0.314, 0.174, 0.144, 0.144, 0.144, 0.176, 0.192, 0.094, 0.082, 0.09, 0.094, 0.193, 0.169, 0.232, 0.237, 0.312, 0.294, 0.408, 0.39, 0.391, 0.35, 0.346, 0.243, 0.283, 0.28, 0.323, 0.452, 0.395, 0.418, 0.413, 0.486, 0.386, 0.458, 0.386, 0.511, 0.392, 0.476, 0.436, 0.554, 0.522, 0.487, 0.522, 0.515, 0.599, 0.587, 0.592, 0.634, 0.661, 0.669, 0.668, 0.651, 0.627, 0.631, 0.65, 0.669, 0.676, 0.676, 0.676, 0.663, 0.653, 0.658, 0.671, 0.684, 0.691, 0.692, 0.69, 0.688, 0.685, 0.682, 0.68, 0.678, 0.674, 0.672, 0.672, 0.674, 0.676, 0.68, 0.681, 0.682, 0.684, 0.685, 0.684, 0.682, 0.682, 0.683, 0.685, 0.685, 0.683, 0.682, 0.684, 0.685, 0.684, 0.68, 0.68, 0.679, 0.679, 0.678, 0.678, 0.679, 0.679, 0.679, 0.679, 0.677, 0.677, 0.677, 0.677, 0.677, 0.678, 0.679, 0.681, 0.681, 0.681, 0.681, 0.679, 0.68, 0.679, 0.679, 0.679, 0.679, 0.678, 0.678, 0.68, 0.681, 0.68, 0.68, 0.681, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.681, 0.681, 0.681, 0.681, 0.68, 0.679, 0.679, 0.68, 0.68, 0.68, 0.68, 0.681, 0.681, 0.681, 0.681, 0.68, 0.679, 0.679, 0.678, 0.678, 0.678, 0.677, 0.676, 0.676, 0.675, 0.675, 0.674, 0.674, 0.674, 0.674, 0.675, 0.676, 0.676, 0.675, 0.675, 0.675, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.673, 0.674, 0.673, 0.674, 0.675, 0.675, 0.675, 0.675, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.675, 0.674, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.674, 0.674, 0.674, 0.673, 0.674, 0.674, 0.674, 0.675, 0.675, 0.674, 0.673, 0.673, 0.673, 0.673, 0.673, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.671, 0.671, 0.671, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.673, 0.673, 0.673, 0.673, 0.672, 0.672, 0.672, 0.673, 0.673, 0.673, 0.673, 0.673, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.671, 0.671, 0.671, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671]
best validation: 0.672
best test: 0.692
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 6
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 1024
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.5909, Train: 91.43%, Valid: 50.00%, Test: 54.10%, Best Valid: 50.00%, Best Test: 54.10%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 66.60%, Test: 67.00%, Best Valid: 69.20%, Best Test: 68.00%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 67.80%, Best Valid: 69.20%, Best Test: 68.00%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 66.70%, Best Valid: 69.20%, Best Test: 68.60%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 66.50%, Best Valid: 69.20%, Best Test: 68.60%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 67.80%, Test: 66.60%, Best Valid: 69.20%, Best Test: 68.60%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 67.40%, Test: 66.40%, Best Valid: 69.20%, Best Test: 68.60%
train_accuracy_list: [0.14285714285714285, 0.22142857142857142, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.14285714285714285, 0.17142857142857143, 0.17857142857142858, 0.14285714285714285, 0.2571428571428571, 0.14285714285714285, 0.22142857142857142, 0.30714285714285716, 0.18571428571428572, 0.22857142857142856, 0.2857142857142857, 0.32857142857142857, 0.2571428571428571, 0.37142857142857144, 0.42142857142857143, 0.4785714285714286, 0.5642857142857143, 0.5285714285714286, 0.6714285714285714, 0.6285714285714286, 0.6428571428571429, 0.6785714285714286, 0.7285714285714285, 0.7, 0.7571428571428571, 0.8285714285714286, 0.8357142857142857, 0.8142857142857143, 0.9142857142857143, 0.8571428571428571, 0.8357142857142857, 0.9285714285714286, 0.95, 0.9642857142857143, 0.9571428571428572, 0.9785714285714285, 0.9857142857142858, 0.9785714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.316, 0.148, 0.072, 0.156, 0.316, 0.162, 0.162, 0.162, 0.058, 0.058, 0.058, 0.058, 0.058, 0.126, 0.316, 0.316, 0.316, 0.316, 0.316, 0.266, 0.072, 0.07, 0.09, 0.154, 0.156, 0.248, 0.162, 0.17, 0.158, 0.124, 0.14, 0.222, 0.248, 0.202, 0.224, 0.346, 0.426, 0.438, 0.344, 0.464, 0.45, 0.39, 0.386, 0.42, 0.394, 0.38, 0.458, 0.494, 0.462, 0.5, 0.488, 0.474, 0.556, 0.558, 0.542, 0.582, 0.646, 0.616, 0.592, 0.646, 0.662, 0.664, 0.662, 0.678, 0.674, 0.678, 0.686, 0.692, 0.692, 0.684, 0.672, 0.66, 0.668, 0.666, 0.672, 0.668, 0.668, 0.668, 0.664, 0.66, 0.658, 0.658, 0.658, 0.658, 0.658, 0.656, 0.658, 0.656, 0.656, 0.66, 0.656, 0.656, 0.656, 0.658, 0.658, 0.66, 0.66, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.668, 0.668, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682, 0.682, 0.684, 0.684, 0.684, 0.682, 0.684, 0.684, 0.686, 0.686, 0.686, 0.684, 0.686, 0.686, 0.688, 0.69, 0.69, 0.69, 0.688, 0.688, 0.686, 0.688, 0.69, 0.692, 0.692, 0.692, 0.69, 0.688, 0.688, 0.688, 0.686, 0.686, 0.68, 0.678, 0.678, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.678, 0.682, 0.682, 0.682, 0.678, 0.678, 0.678, 0.68, 0.68, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676]
test_accuracy_list: [0.319, 0.166, 0.091, 0.144, 0.319, 0.149, 0.149, 0.149, 0.064, 0.064, 0.064, 0.064, 0.064, 0.133, 0.319, 0.319, 0.319, 0.319, 0.317, 0.299, 0.091, 0.091, 0.112, 0.174, 0.144, 0.219, 0.148, 0.17, 0.153, 0.124, 0.134, 0.198, 0.224, 0.215, 0.269, 0.385, 0.444, 0.454, 0.399, 0.488, 0.456, 0.384, 0.379, 0.42, 0.414, 0.398, 0.436, 0.504, 0.499, 0.541, 0.493, 0.492, 0.573, 0.593, 0.573, 0.592, 0.663, 0.642, 0.605, 0.657, 0.68, 0.672, 0.669, 0.68, 0.677, 0.669, 0.676, 0.677, 0.676, 0.67, 0.661, 0.666, 0.666, 0.672, 0.673, 0.671, 0.673, 0.671, 0.669, 0.663, 0.663, 0.662, 0.66, 0.66, 0.659, 0.658, 0.658, 0.657, 0.658, 0.657, 0.659, 0.66, 0.659, 0.66, 0.663, 0.664, 0.665, 0.665, 0.667, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.673, 0.673, 0.674, 0.674, 0.674, 0.676, 0.676, 0.678, 0.678, 0.678, 0.677, 0.677, 0.677, 0.677, 0.674, 0.673, 0.672, 0.672, 0.672, 0.672, 0.672, 0.671, 0.671, 0.671, 0.671, 0.673, 0.673, 0.672, 0.672, 0.672, 0.672, 0.671, 0.674, 0.674, 0.674, 0.676, 0.678, 0.678, 0.677, 0.675, 0.674, 0.675, 0.678, 0.678, 0.678, 0.679, 0.681, 0.681, 0.681, 0.682, 0.683, 0.683, 0.684, 0.685, 0.686, 0.683, 0.683, 0.683, 0.682, 0.679, 0.677, 0.677, 0.675, 0.674, 0.674, 0.673, 0.673, 0.674, 0.674, 0.674, 0.673, 0.674, 0.673, 0.673, 0.672, 0.675, 0.675, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.669, 0.669, 0.669, 0.669, 0.668, 0.668, 0.668, 0.668, 0.668, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.666, 0.666, 0.666, 0.666, 0.666, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.665, 0.665, 0.665, 0.665, 0.665, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.665, 0.665, 0.665, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.665, 0.665, 0.665, 0.665, 0.665, 0.665, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666]
best validation: 0.692
best test: 0.686
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 6
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 1024
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.4798, Train: 90.71%, Valid: 60.00%, Test: 61.20%, Best Valid: 60.40%, Best Test: 61.90%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.60%, Test: 62.50%, Best Valid: 66.00%, Best Test: 66.50%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 63.00%, Test: 62.90%, Best Valid: 66.00%, Best Test: 66.50%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 62.40%, Test: 63.10%, Best Valid: 66.00%, Best Test: 66.50%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 62.40%, Test: 63.40%, Best Valid: 66.00%, Best Test: 66.50%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 62.00%, Test: 63.80%, Best Valid: 66.00%, Best Test: 66.50%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 62.60%, Test: 64.00%, Best Valid: 66.00%, Best Test: 66.50%
train_accuracy_list: [0.17142857142857143, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.1357142857142857, 0.1357142857142857, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.15, 0.1357142857142857, 0.14285714285714285, 0.15, 0.2357142857142857, 0.15714285714285714, 0.2642857142857143, 0.17857142857142858, 0.16428571428571428, 0.21428571428571427, 0.36428571428571427, 0.37857142857142856, 0.2714285714285714, 0.32142857142857145, 0.37857142857142856, 0.42142857142857143, 0.5285714285714286, 0.5857142857142857, 0.5428571428571428, 0.7, 0.7357142857142858, 0.7642857142857142, 0.85, 0.8428571428571429, 0.8785714285714286, 0.8571428571428571, 0.9071428571428571, 0.9214285714285714, 0.95, 0.9714285714285714, 0.9785714285714285, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.072, 0.316, 0.156, 0.072, 0.058, 0.122, 0.316, 0.316, 0.316, 0.316, 0.114, 0.114, 0.114, 0.114, 0.12, 0.12, 0.058, 0.058, 0.06, 0.06, 0.062, 0.162, 0.136, 0.124, 0.128, 0.32, 0.316, 0.304, 0.158, 0.174, 0.082, 0.074, 0.088, 0.178, 0.346, 0.304, 0.238, 0.348, 0.282, 0.322, 0.384, 0.388, 0.474, 0.52, 0.506, 0.576, 0.594, 0.548, 0.604, 0.6, 0.604, 0.616, 0.612, 0.602, 0.64, 0.622, 0.636, 0.642, 0.642, 0.654, 0.658, 0.638, 0.66, 0.654, 0.642, 0.642, 0.648, 0.644, 0.656, 0.634, 0.604, 0.616, 0.618, 0.62, 0.618, 0.62, 0.622, 0.628, 0.624, 0.622, 0.62, 0.618, 0.614, 0.618, 0.612, 0.608, 0.608, 0.608, 0.608, 0.606, 0.606, 0.606, 0.61, 0.61, 0.61, 0.608, 0.608, 0.61, 0.614, 0.616, 0.618, 0.624, 0.618, 0.618, 0.618, 0.616, 0.618, 0.616, 0.62, 0.622, 0.626, 0.628, 0.628, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.628, 0.628, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.628, 0.628, 0.628, 0.628, 0.632, 0.632, 0.632, 0.632, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.628, 0.628, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.624, 0.624, 0.624, 0.624, 0.624, 0.622, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.624, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.622, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.618, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.622, 0.624, 0.622, 0.62, 0.62, 0.62, 0.62, 0.624, 0.624, 0.624, 0.622, 0.62, 0.62, 0.622, 0.624, 0.626, 0.626, 0.622, 0.622, 0.624, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626, 0.626]
test_accuracy_list: [0.075, 0.319, 0.145, 0.091, 0.064, 0.13, 0.319, 0.319, 0.319, 0.317, 0.103, 0.103, 0.103, 0.103, 0.117, 0.129, 0.064, 0.064, 0.064, 0.064, 0.078, 0.15, 0.157, 0.133, 0.136, 0.322, 0.32, 0.317, 0.146, 0.192, 0.111, 0.095, 0.105, 0.198, 0.371, 0.313, 0.255, 0.365, 0.29, 0.332, 0.38, 0.377, 0.457, 0.509, 0.501, 0.593, 0.619, 0.534, 0.616, 0.612, 0.603, 0.621, 0.617, 0.625, 0.654, 0.625, 0.646, 0.648, 0.645, 0.665, 0.664, 0.634, 0.664, 0.65, 0.641, 0.633, 0.633, 0.657, 0.654, 0.652, 0.632, 0.631, 0.638, 0.645, 0.637, 0.644, 0.638, 0.63, 0.629, 0.628, 0.63, 0.627, 0.623, 0.624, 0.625, 0.62, 0.619, 0.619, 0.618, 0.618, 0.619, 0.62, 0.621, 0.624, 0.625, 0.626, 0.627, 0.626, 0.627, 0.625, 0.627, 0.629, 0.631, 0.631, 0.628, 0.627, 0.627, 0.629, 0.632, 0.633, 0.634, 0.635, 0.635, 0.635, 0.634, 0.634, 0.635, 0.634, 0.634, 0.634, 0.633, 0.633, 0.629, 0.629, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.631, 0.633, 0.632, 0.631, 0.632, 0.633, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.632, 0.631, 0.63, 0.63, 0.63, 0.629, 0.629, 0.629, 0.629, 0.63, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.63, 0.63, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.629, 0.63, 0.63, 0.63, 0.63, 0.63, 0.629, 0.629, 0.629, 0.63, 0.63, 0.63, 0.63, 0.63, 0.631, 0.631, 0.631, 0.631, 0.631, 0.63, 0.63, 0.63, 0.63, 0.63, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.631, 0.632, 0.632, 0.632, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.633, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.634, 0.635, 0.635, 0.635, 0.635, 0.635, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.636, 0.637, 0.636, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.637, 0.638, 0.638, 0.638, 0.638, 0.638, 0.639, 0.639, 0.639, 0.638, 0.638, 0.638, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.64, 0.64, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.639, 0.64, 0.64, 0.64, 0.639, 0.638, 0.638, 0.639, 0.64, 0.64, 0.64, 0.64, 0.64, 0.639, 0.638, 0.639, 0.64, 0.639, 0.64, 0.64, 0.64, 0.638, 0.638, 0.64, 0.64, 0.64, 0.64, 0.64, 0.638, 0.638, 0.638, 0.639, 0.639, 0.64, 0.639, 0.639, 0.639, 0.639, 0.638, 0.639, 0.639, 0.64, 0.64, 0.64, 0.639, 0.64, 0.639, 0.639, 0.639, 0.641, 0.64, 0.64, 0.641, 0.641, 0.641, 0.639, 0.639, 0.639, 0.639]
best validation: 0.66
best test: 0.665
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 7
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 2048
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.1295, Train: 99.29%, Valid: 66.40%, Test: 67.70%, Best Valid: 66.40%, Best Test: 68.40%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60%, Test: 66.90%, Best Valid: 68.00%, Best Test: 68.40%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 67.10%, Best Valid: 68.00%, Best Test: 68.40%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 66.60%, Test: 66.90%, Best Valid: 68.00%, Best Test: 68.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 67.00%, Best Valid: 68.00%, Best Test: 68.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 67.00%, Test: 66.90%, Best Valid: 68.00%, Best Test: 68.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 67.20%, Test: 66.80%, Best Valid: 68.00%, Best Test: 68.40%
train_accuracy_list: [0.17857142857142858, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.17142857142857143, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.15714285714285714, 0.16428571428571428, 0.14285714285714285, 0.15, 0.15714285714285714, 0.2357142857142857, 0.15, 0.15714285714285714, 0.42142857142857143, 0.2, 0.2785714285714286, 0.35, 0.45714285714285713, 0.42142857142857143, 0.55, 0.5714285714285714, 0.5928571428571429, 0.6214285714285714, 0.6428571428571429, 0.75, 0.7428571428571429, 0.8214285714285714, 0.8357142857142857, 0.7928571428571428, 0.8142857142857143, 0.8071428571428572, 0.9071428571428571, 0.9357142857142857, 0.9571428571428572, 0.9714285714285714, 0.9642857142857143, 0.9714285714285714, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.324, 0.316, 0.162, 0.156, 0.122, 0.114, 0.06, 0.06, 0.058, 0.058, 0.058, 0.058, 0.058, 0.058, 0.126, 0.156, 0.132, 0.122, 0.114, 0.116, 0.122, 0.322, 0.168, 0.202, 0.226, 0.074, 0.112, 0.266, 0.376, 0.394, 0.484, 0.498, 0.446, 0.466, 0.56, 0.592, 0.542, 0.596, 0.616, 0.518, 0.59, 0.614, 0.612, 0.61, 0.638, 0.65, 0.644, 0.63, 0.66, 0.664, 0.662, 0.646, 0.644, 0.672, 0.658, 0.664, 0.666, 0.664, 0.652, 0.652, 0.648, 0.65, 0.648, 0.66, 0.664, 0.672, 0.68, 0.676, 0.676, 0.674, 0.674, 0.678, 0.68, 0.676, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.66, 0.658, 0.654, 0.652, 0.652, 0.656, 0.66, 0.66, 0.666, 0.666, 0.668, 0.67, 0.664, 0.664, 0.664, 0.664, 0.666, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.666, 0.664, 0.658, 0.656, 0.658, 0.66, 0.662, 0.664, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.664, 0.664, 0.662, 0.662, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.666, 0.666, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672]
test_accuracy_list: [0.325, 0.319, 0.149, 0.144, 0.13, 0.103, 0.064, 0.071, 0.064, 0.064, 0.064, 0.064, 0.064, 0.063, 0.159, 0.144, 0.165, 0.11, 0.103, 0.104, 0.114, 0.324, 0.155, 0.193, 0.255, 0.084, 0.125, 0.264, 0.422, 0.412, 0.464, 0.485, 0.438, 0.446, 0.538, 0.571, 0.571, 0.609, 0.638, 0.563, 0.624, 0.637, 0.629, 0.624, 0.677, 0.682, 0.662, 0.662, 0.684, 0.677, 0.673, 0.657, 0.658, 0.672, 0.666, 0.672, 0.661, 0.662, 0.66, 0.659, 0.665, 0.663, 0.667, 0.668, 0.665, 0.672, 0.676, 0.679, 0.679, 0.673, 0.676, 0.678, 0.681, 0.676, 0.678, 0.674, 0.669, 0.669, 0.671, 0.674, 0.673, 0.673, 0.666, 0.661, 0.658, 0.657, 0.657, 0.661, 0.667, 0.669, 0.673, 0.673, 0.675, 0.669, 0.669, 0.669, 0.667, 0.667, 0.668, 0.669, 0.669, 0.672, 0.673, 0.673, 0.673, 0.67, 0.67, 0.669, 0.666, 0.666, 0.665, 0.665, 0.663, 0.663, 0.662, 0.664, 0.669, 0.669, 0.67, 0.671, 0.671, 0.671, 0.67, 0.668, 0.667, 0.669, 0.669, 0.671, 0.672, 0.672, 0.673, 0.671, 0.672, 0.673, 0.673, 0.673, 0.673, 0.673, 0.672, 0.672, 0.672, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.671, 0.671, 0.672, 0.672, 0.671, 0.671, 0.671, 0.671, 0.67, 0.67, 0.669, 0.669, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.669, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.67, 0.67, 0.67, 0.67, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.669, 0.668, 0.668, 0.668, 0.668, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.668, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667, 0.667]
best validation: 0.68
best test: 0.684
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 7
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 2048
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.4161, Train: 91.43%, Valid: 51.40%, Test: 54.20%, Best Valid: 56.00%, Best Test: 59.40%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 68.60%, Test: 68.40%, Best Valid: 68.80%, Best Test: 68.60%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.80%, Best Valid: 68.80%, Best Test: 68.90%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.70%, Best Valid: 68.80%, Best Test: 68.90%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 68.60%, Best Valid: 68.80%, Best Test: 68.90%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 69.00%, Test: 68.60%, Best Valid: 69.00%, Best Test: 68.90%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 69.00%, Test: 68.70%, Best Valid: 69.00%, Best Test: 68.90%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.21428571428571427, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.16428571428571428, 0.14285714285714285, 0.15, 0.2785714285714286, 0.14285714285714285, 0.14285714285714285, 0.2, 0.14285714285714285, 0.30714285714285716, 0.18571428571428572, 0.22142857142857142, 0.15, 0.2, 0.2785714285714286, 0.2857142857142857, 0.35, 0.5071428571428571, 0.5071428571428571, 0.7, 0.6785714285714286, 0.6642857142857143, 0.7071428571428572, 0.5428571428571428, 0.6285714285714286, 0.75, 0.7214285714285714, 0.6785714285714286, 0.8214285714285714, 0.8357142857142857, 0.8214285714285714, 0.9142857142857143, 0.8571428571428571, 0.8785714285714286, 0.9071428571428571, 0.9142857142857143, 0.9357142857142857, 0.9357142857142857, 0.9285714285714286, 0.9642857142857143, 0.9785714285714285, 0.9785714285714285, 0.9857142857142858, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.122, 0.122, 0.338, 0.156, 0.072, 0.122, 0.122, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.058, 0.076, 0.114, 0.114, 0.15, 0.156, 0.156, 0.178, 0.07, 0.302, 0.32, 0.318, 0.198, 0.238, 0.358, 0.334, 0.278, 0.334, 0.368, 0.384, 0.474, 0.486, 0.43, 0.356, 0.426, 0.434, 0.352, 0.304, 0.46, 0.462, 0.46, 0.536, 0.506, 0.558, 0.56, 0.514, 0.574, 0.606, 0.616, 0.614, 0.614, 0.588, 0.592, 0.588, 0.592, 0.628, 0.64, 0.654, 0.642, 0.618, 0.612, 0.634, 0.648, 0.664, 0.672, 0.67, 0.668, 0.672, 0.678, 0.678, 0.676, 0.674, 0.666, 0.668, 0.66, 0.652, 0.656, 0.666, 0.666, 0.67, 0.668, 0.674, 0.674, 0.674, 0.676, 0.678, 0.678, 0.68, 0.68, 0.68, 0.682, 0.684, 0.686, 0.688, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.688, 0.688, 0.686, 0.684, 0.684, 0.682, 0.682, 0.68, 0.68, 0.678, 0.678, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69]
test_accuracy_list: [0.13, 0.13, 0.333, 0.144, 0.091, 0.13, 0.13, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.147, 0.064, 0.083, 0.103, 0.103, 0.172, 0.144, 0.144, 0.146, 0.093, 0.313, 0.331, 0.319, 0.185, 0.255, 0.356, 0.359, 0.313, 0.364, 0.387, 0.409, 0.474, 0.469, 0.436, 0.338, 0.388, 0.411, 0.376, 0.334, 0.467, 0.468, 0.493, 0.583, 0.526, 0.594, 0.583, 0.542, 0.572, 0.625, 0.627, 0.632, 0.623, 0.615, 0.6, 0.601, 0.619, 0.632, 0.653, 0.664, 0.662, 0.619, 0.604, 0.63, 0.659, 0.664, 0.665, 0.668, 0.669, 0.67, 0.672, 0.67, 0.674, 0.677, 0.677, 0.674, 0.671, 0.666, 0.661, 0.668, 0.671, 0.672, 0.673, 0.676, 0.68, 0.682, 0.684, 0.684, 0.683, 0.683, 0.681, 0.681, 0.684, 0.686, 0.686, 0.686, 0.683, 0.684, 0.683, 0.686, 0.684, 0.684, 0.685, 0.687, 0.687, 0.687, 0.686, 0.686, 0.686, 0.686, 0.685, 0.687, 0.688, 0.688, 0.688, 0.688, 0.689, 0.688, 0.687, 0.686, 0.685, 0.686, 0.686, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.686, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.687, 0.687, 0.687, 0.688, 0.688, 0.688, 0.688, 0.688, 0.689, 0.688, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.685, 0.685, 0.685, 0.685, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.685, 0.686, 0.686, 0.686, 0.686, 0.686, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687, 0.687]
best validation: 0.692
best test: 0.689
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 7
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 2048
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.4609, Train: 88.57%, Valid: 49.00%, Test: 56.60%, Best Valid: 54.60%, Best Test: 58.40%
Epoch: 100, Loss: 0.0001, Train: 100.00%, Valid: 69.20%, Test: 68.50%, Best Valid: 69.80%, Best Test: 70.20%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 68.20%, Best Valid: 69.80%, Best Test: 70.20%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.80%, Test: 68.30%, Best Valid: 69.80%, Best Test: 70.20%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.40%, Best Valid: 69.80%, Best Test: 70.20%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.10%, Best Valid: 69.80%, Best Test: 70.20%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 68.40%, Test: 68.30%, Best Valid: 69.80%, Best Test: 70.20%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.21428571428571427, 0.15714285714285714, 0.15714285714285714, 0.14285714285714285, 0.14285714285714285, 0.15, 0.2, 0.15, 0.25, 0.2785714285714286, 0.35714285714285715, 0.32142857142857145, 0.25, 0.35, 0.38571428571428573, 0.37857142857142856, 0.38571428571428573, 0.40714285714285714, 0.40714285714285714, 0.45, 0.6, 0.6214285714285714, 0.8214285714285714, 0.6714285714285714, 0.7857142857142857, 0.7428571428571429, 0.7857142857142857, 0.7714285714285715, 0.75, 0.8714285714285714, 0.8214285714285714, 0.8071428571428572, 0.8357142857142857, 0.9071428571428571, 0.8857142857142857, 0.9285714285714286, 0.9428571428571428, 0.9571428571428572, 0.95, 0.9571428571428572, 0.9714285714285714, 0.9714285714285714, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.058, 0.058, 0.122, 0.156, 0.114, 0.072, 0.072, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.074, 0.284, 0.102, 0.308, 0.316, 0.316, 0.162, 0.156, 0.06, 0.102, 0.104, 0.114, 0.132, 0.142, 0.23, 0.238, 0.198, 0.236, 0.246, 0.258, 0.268, 0.322, 0.37, 0.546, 0.388, 0.504, 0.456, 0.488, 0.362, 0.374, 0.472, 0.498, 0.464, 0.452, 0.534, 0.49, 0.54, 0.63, 0.658, 0.688, 0.682, 0.646, 0.598, 0.618, 0.674, 0.666, 0.682, 0.684, 0.674, 0.666, 0.67, 0.676, 0.676, 0.674, 0.672, 0.678, 0.678, 0.682, 0.674, 0.67, 0.684, 0.69, 0.69, 0.694, 0.69, 0.692, 0.696, 0.696, 0.698, 0.698, 0.698, 0.694, 0.692, 0.692, 0.692, 0.692, 0.69, 0.692, 0.692, 0.694, 0.696, 0.696, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.692, 0.69, 0.69, 0.69, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.688, 0.688, 0.688, 0.69, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.692, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682]
test_accuracy_list: [0.064, 0.064, 0.13, 0.144, 0.103, 0.091, 0.091, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.149, 0.091, 0.304, 0.121, 0.317, 0.318, 0.317, 0.144, 0.152, 0.066, 0.113, 0.122, 0.143, 0.131, 0.152, 0.23, 0.242, 0.24, 0.261, 0.275, 0.285, 0.277, 0.347, 0.408, 0.584, 0.435, 0.542, 0.453, 0.5, 0.415, 0.404, 0.492, 0.49, 0.446, 0.458, 0.582, 0.566, 0.604, 0.649, 0.661, 0.681, 0.702, 0.681, 0.649, 0.659, 0.678, 0.686, 0.679, 0.685, 0.691, 0.69, 0.684, 0.684, 0.658, 0.651, 0.658, 0.654, 0.67, 0.681, 0.668, 0.664, 0.67, 0.679, 0.683, 0.683, 0.68, 0.674, 0.674, 0.675, 0.676, 0.677, 0.686, 0.685, 0.684, 0.686, 0.686, 0.687, 0.689, 0.691, 0.691, 0.69, 0.686, 0.686, 0.684, 0.687, 0.687, 0.685, 0.683, 0.683, 0.683, 0.682, 0.683, 0.682, 0.685, 0.685, 0.685, 0.685, 0.684, 0.686, 0.685, 0.686, 0.687, 0.688, 0.688, 0.689, 0.688, 0.688, 0.687, 0.685, 0.685, 0.684, 0.684, 0.682, 0.683, 0.684, 0.684, 0.683, 0.683, 0.683, 0.683, 0.684, 0.684, 0.682, 0.681, 0.68, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.684, 0.684, 0.684, 0.683, 0.683, 0.683, 0.682, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.684, 0.683, 0.683, 0.682, 0.682, 0.682, 0.682, 0.683, 0.683, 0.683, 0.683, 0.682, 0.683, 0.683, 0.684, 0.684, 0.683, 0.683, 0.683, 0.684, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.683, 0.683, 0.684, 0.684, 0.684, 0.683, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.681, 0.681, 0.681, 0.681, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.681, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.683, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.683, 0.683, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684]
best validation: 0.698
best test: 0.702
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 8
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 4096
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.2995, Train: 95.71%, Valid: 64.60%, Test: 66.90%, Best Valid: 64.80%, Best Test: 66.90%
Epoch: 100, Loss: 0.0017, Train: 100.00%, Valid: 67.80%, Test: 67.90%, Best Valid: 68.40%, Best Test: 68.20%
Epoch: 150, Loss: 0.0004, Train: 100.00%, Valid: 67.80%, Test: 67.50%, Best Valid: 68.40%, Best Test: 68.40%
Epoch: 200, Loss: 0.0001, Train: 100.00%, Valid: 67.40%, Test: 67.00%, Best Valid: 68.40%, Best Test: 68.40%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 67.80%, Best Valid: 68.40%, Best Test: 68.40%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 66.80%, Test: 67.70%, Best Valid: 68.40%, Best Test: 68.40%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 66.40%, Test: 67.70%, Best Valid: 68.40%, Best Test: 68.40%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15, 0.15, 0.14285714285714285, 0.16428571428571428, 0.15714285714285714, 0.22142857142857142, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.22857142857142856, 0.18571428571428572, 0.2785714285714286, 0.2714285714285714, 0.32857142857142857, 0.34285714285714286, 0.30714285714285716, 0.25, 0.40714285714285714, 0.37142857142857144, 0.4, 0.5142857142857142, 0.5642857142857143, 0.65, 0.5071428571428571, 0.7785714285714286, 0.6785714285714286, 0.75, 0.7714285714285715, 0.7357142857142858, 0.7714285714285715, 0.7857142857142857, 0.8357142857142857, 0.8428571428571429, 0.8928571428571429, 0.9071428571428571, 0.9214285714285714, 0.9428571428571428, 0.9357142857142857, 0.9571428571428572, 0.9571428571428572, 0.9571428571428572, 0.9714285714285714, 0.9571428571428572, 0.9357142857142857, 0.8714285714285714, 0.8357142857142857, 0.9785714285714285, 0.9642857142857143, 0.9428571428571428, 0.9785714285714285, 0.9785714285714285, 0.9714285714285714, 0.9714285714285714, 0.9857142857142858, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.316, 0.122, 0.114, 0.072, 0.31, 0.316, 0.316, 0.162, 0.162, 0.164, 0.316, 0.314, 0.156, 0.122, 0.138, 0.156, 0.276, 0.316, 0.058, 0.058, 0.086, 0.118, 0.154, 0.13, 0.202, 0.252, 0.166, 0.122, 0.274, 0.25, 0.252, 0.412, 0.408, 0.516, 0.452, 0.57, 0.504, 0.56, 0.554, 0.548, 0.544, 0.54, 0.58, 0.584, 0.608, 0.62, 0.628, 0.642, 0.648, 0.646, 0.632, 0.656, 0.656, 0.624, 0.634, 0.51, 0.536, 0.666, 0.64, 0.574, 0.658, 0.65, 0.614, 0.652, 0.646, 0.638, 0.638, 0.638, 0.65, 0.674, 0.662, 0.666, 0.656, 0.66, 0.666, 0.668, 0.676, 0.67, 0.674, 0.668, 0.67, 0.67, 0.68, 0.682, 0.684, 0.678, 0.67, 0.68, 0.676, 0.678, 0.678, 0.676, 0.674, 0.676, 0.676, 0.678, 0.674, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.68, 0.682, 0.682, 0.68, 0.678, 0.68, 0.68, 0.68, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.676, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.676, 0.674, 0.674, 0.674, 0.676, 0.678, 0.676, 0.676, 0.676, 0.678, 0.678, 0.678, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.676, 0.678, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.674, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.674, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.672, 0.674, 0.672, 0.672, 0.674, 0.674, 0.674, 0.674, 0.674, 0.676, 0.674, 0.674, 0.668, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.668, 0.668, 0.668, 0.668, 0.668, 0.67, 0.67, 0.67, 0.67, 0.668, 0.67, 0.67, 0.668, 0.666, 0.67, 0.672, 0.672, 0.67, 0.668, 0.67, 0.672, 0.672, 0.666, 0.666, 0.666, 0.668, 0.668, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.664, 0.666, 0.666, 0.664, 0.664, 0.662, 0.664, 0.664, 0.664, 0.664, 0.666, 0.664, 0.664, 0.662, 0.662, 0.662, 0.662, 0.668, 0.666, 0.664, 0.666, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.666, 0.666, 0.666, 0.666, 0.664, 0.664, 0.664, 0.664, 0.664, 0.666, 0.666, 0.664, 0.664, 0.664, 0.664, 0.664, 0.666, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.662, 0.662, 0.662, 0.662, 0.662]
test_accuracy_list: [0.319, 0.13, 0.103, 0.091, 0.317, 0.319, 0.319, 0.149, 0.149, 0.149, 0.318, 0.319, 0.143, 0.13, 0.127, 0.145, 0.262, 0.319, 0.064, 0.064, 0.08, 0.107, 0.148, 0.153, 0.214, 0.287, 0.191, 0.14, 0.286, 0.256, 0.267, 0.437, 0.415, 0.502, 0.456, 0.585, 0.488, 0.564, 0.549, 0.574, 0.552, 0.537, 0.586, 0.607, 0.616, 0.645, 0.654, 0.655, 0.667, 0.669, 0.656, 0.664, 0.677, 0.661, 0.638, 0.519, 0.512, 0.676, 0.651, 0.576, 0.673, 0.65, 0.589, 0.611, 0.663, 0.626, 0.631, 0.645, 0.66, 0.671, 0.663, 0.639, 0.618, 0.619, 0.644, 0.667, 0.674, 0.676, 0.673, 0.674, 0.676, 0.673, 0.679, 0.682, 0.681, 0.673, 0.671, 0.668, 0.665, 0.664, 0.66, 0.662, 0.661, 0.663, 0.667, 0.669, 0.665, 0.672, 0.675, 0.679, 0.681, 0.68, 0.683, 0.683, 0.682, 0.683, 0.683, 0.684, 0.682, 0.68, 0.682, 0.68, 0.68, 0.679, 0.679, 0.679, 0.68, 0.68, 0.679, 0.68, 0.68, 0.68, 0.678, 0.678, 0.678, 0.679, 0.679, 0.679, 0.679, 0.679, 0.678, 0.677, 0.676, 0.677, 0.675, 0.673, 0.673, 0.674, 0.673, 0.672, 0.673, 0.673, 0.673, 0.674, 0.673, 0.672, 0.673, 0.673, 0.675, 0.675, 0.676, 0.676, 0.676, 0.675, 0.675, 0.675, 0.676, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.674, 0.675, 0.676, 0.675, 0.674, 0.674, 0.674, 0.673, 0.672, 0.672, 0.672, 0.671, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.672, 0.673, 0.673, 0.672, 0.672, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.67, 0.67, 0.671, 0.671, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.671, 0.671, 0.671, 0.671, 0.671, 0.671, 0.672, 0.672, 0.672, 0.672, 0.672, 0.671, 0.669, 0.67, 0.668, 0.669, 0.669, 0.669, 0.668, 0.67, 0.671, 0.673, 0.674, 0.673, 0.673, 0.673, 0.673, 0.674, 0.674, 0.673, 0.674, 0.677, 0.676, 0.677, 0.678, 0.678, 0.679, 0.679, 0.677, 0.678, 0.68, 0.681, 0.68, 0.684, 0.683, 0.682, 0.684, 0.681, 0.681, 0.682, 0.681, 0.681, 0.68, 0.68, 0.68, 0.679, 0.678, 0.68, 0.679, 0.678, 0.68, 0.679, 0.679, 0.679, 0.68, 0.68, 0.68, 0.678, 0.677, 0.678, 0.679, 0.678, 0.677, 0.676, 0.676, 0.676, 0.677, 0.676, 0.677, 0.676, 0.677, 0.677, 0.677, 0.676, 0.675, 0.676, 0.676, 0.676, 0.675, 0.677, 0.676, 0.675, 0.674, 0.675, 0.674, 0.675, 0.675, 0.674, 0.676, 0.676, 0.674, 0.675, 0.676, 0.676, 0.676, 0.677, 0.675, 0.676, 0.676, 0.675, 0.675, 0.677, 0.675, 0.675, 0.676, 0.676, 0.676, 0.676, 0.676, 0.675, 0.676, 0.676, 0.674, 0.674, 0.675, 0.677, 0.677, 0.677, 0.677, 0.676, 0.676, 0.676, 0.677, 0.677, 0.677, 0.676, 0.676, 0.676, 0.676, 0.677, 0.677, 0.677, 0.676, 0.676, 0.679, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.677, 0.676, 0.677, 0.678, 0.677, 0.676, 0.677, 0.677, 0.677, 0.677, 0.677, 0.678, 0.679, 0.679, 0.678, 0.677, 0.677, 0.677, 0.678, 0.679, 0.68, 0.68, 0.68, 0.68, 0.679, 0.679, 0.678, 0.678, 0.678, 0.679, 0.679, 0.679, 0.679, 0.678, 0.678, 0.678, 0.678, 0.678]
best validation: 0.684
best test: 0.684
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 8
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 4096
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.1178, Train: 75.71%, Valid: 43.00%, Test: 42.10%, Best Valid: 66.80%, Best Test: 69.90%
Epoch: 100, Loss: 0.0004, Train: 100.00%, Valid: 68.60%, Test: 70.70%, Best Valid: 72.00%, Best Test: 74.10%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 69.40%, Test: 70.50%, Best Valid: 72.00%, Best Test: 74.10%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 68.60%, Test: 70.00%, Best Valid: 72.00%, Best Test: 74.10%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 69.40%, Best Valid: 72.00%, Best Test: 74.10%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 69.30%, Best Valid: 72.00%, Best Test: 74.10%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 68.00%, Test: 69.20%, Best Valid: 72.00%, Best Test: 74.10%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.15, 0.15714285714285714, 0.14285714285714285, 0.18571428571428572, 0.14285714285714285, 0.17857142857142858, 0.38571428571428573, 0.15714285714285714, 0.17142857142857143, 0.2714285714285714, 0.2, 0.4357142857142857, 0.4785714285714286, 0.4142857142857143, 0.3142857142857143, 0.6642857142857143, 0.42857142857142855, 0.5285714285714286, 0.5857142857142857, 0.7357142857142858, 0.7142857142857143, 0.6714285714285714, 0.6571428571428571, 0.9, 0.75, 0.7857142857142857, 0.9285714285714286, 0.9214285714285714, 0.9142857142857143, 0.9714285714285714, 0.9714285714285714, 0.9714285714285714, 0.9714285714285714, 0.9714285714285714, 0.9928571428571429, 0.9928571428571429, 1.0, 0.9642857142857143, 0.8571428571428571, 0.7357142857142858, 0.9857142857142858, 0.6714285714285714, 0.9571428571428572, 0.7571428571428571, 0.9142857142857143, 1.0, 0.9928571428571429, 0.9357142857142857, 0.9214285714285714, 0.9857142857142858, 0.9857142857142858, 0.9928571428571429, 0.9928571428571429, 0.9857142857142858, 0.9714285714285714, 0.9785714285714285, 0.9928571428571429, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.122, 0.114, 0.316, 0.058, 0.072, 0.072, 0.156, 0.156, 0.122, 0.162, 0.316, 0.186, 0.386, 0.124, 0.07, 0.116, 0.178, 0.244, 0.402, 0.326, 0.222, 0.592, 0.412, 0.184, 0.2, 0.452, 0.548, 0.552, 0.478, 0.566, 0.488, 0.444, 0.522, 0.572, 0.586, 0.634, 0.63, 0.652, 0.638, 0.63, 0.644, 0.648, 0.668, 0.59, 0.646, 0.458, 0.628, 0.502, 0.54, 0.43, 0.512, 0.646, 0.718, 0.682, 0.678, 0.718, 0.72, 0.702, 0.67, 0.638, 0.61, 0.608, 0.614, 0.628, 0.644, 0.652, 0.67, 0.678, 0.68, 0.684, 0.68, 0.682, 0.684, 0.682, 0.684, 0.684, 0.686, 0.686, 0.678, 0.68, 0.68, 0.684, 0.69, 0.69, 0.698, 0.696, 0.694, 0.69, 0.694, 0.692, 0.688, 0.69, 0.684, 0.67, 0.67, 0.674, 0.68, 0.686, 0.686, 0.686, 0.688, 0.688, 0.688, 0.69, 0.692, 0.692, 0.694, 0.692, 0.692, 0.698, 0.7, 0.698, 0.69, 0.69, 0.69, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.688, 0.688, 0.69, 0.69, 0.692, 0.692, 0.692, 0.692, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.694, 0.694, 0.692, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.692, 0.692, 0.692, 0.692, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.688, 0.686, 0.686, 0.688, 0.688, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.686, 0.684, 0.684, 0.684, 0.682, 0.682, 0.684, 0.684, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.684, 0.684, 0.684, 0.684, 0.684, 0.684, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.682, 0.682, 0.682, 0.682, 0.682, 0.682, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68]
test_accuracy_list: [0.13, 0.103, 0.319, 0.064, 0.091, 0.091, 0.148, 0.149, 0.13, 0.157, 0.319, 0.182, 0.38, 0.131, 0.069, 0.118, 0.174, 0.286, 0.408, 0.329, 0.18, 0.569, 0.438, 0.237, 0.24, 0.497, 0.57, 0.568, 0.485, 0.619, 0.54, 0.477, 0.535, 0.613, 0.655, 0.635, 0.633, 0.667, 0.658, 0.648, 0.649, 0.682, 0.699, 0.597, 0.664, 0.451, 0.653, 0.507, 0.552, 0.421, 0.502, 0.656, 0.719, 0.708, 0.713, 0.725, 0.741, 0.722, 0.693, 0.671, 0.665, 0.653, 0.644, 0.656, 0.673, 0.689, 0.706, 0.714, 0.721, 0.727, 0.729, 0.715, 0.708, 0.708, 0.709, 0.708, 0.703, 0.706, 0.708, 0.703, 0.702, 0.703, 0.702, 0.705, 0.707, 0.709, 0.714, 0.715, 0.717, 0.714, 0.711, 0.709, 0.701, 0.694, 0.694, 0.695, 0.701, 0.705, 0.706, 0.707, 0.705, 0.702, 0.705, 0.705, 0.705, 0.707, 0.708, 0.709, 0.709, 0.707, 0.706, 0.705, 0.705, 0.704, 0.704, 0.703, 0.703, 0.702, 0.701, 0.702, 0.702, 0.702, 0.702, 0.705, 0.704, 0.704, 0.703, 0.705, 0.706, 0.706, 0.707, 0.707, 0.703, 0.704, 0.704, 0.703, 0.702, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.703, 0.704, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.705, 0.703, 0.702, 0.703, 0.704, 0.704, 0.702, 0.702, 0.702, 0.702, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.701, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.699, 0.699, 0.699, 0.699, 0.699, 0.699, 0.699, 0.699, 0.699, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.698, 0.697, 0.698, 0.697, 0.698, 0.697, 0.697, 0.697, 0.696, 0.696, 0.696, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.695, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.692, 0.693, 0.693, 0.693, 0.693, 0.694, 0.693, 0.693, 0.692, 0.693, 0.694, 0.694, 0.693, 0.694, 0.693, 0.693, 0.693, 0.693, 0.693, 0.693, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.694, 0.693, 0.693, 0.693, 0.693, 0.692, 0.692, 0.692, 0.692, 0.692, 0.692, 0.691, 0.691, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.689, 0.689, 0.689, 0.689, 0.689, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.689, 0.688, 0.688, 0.688, 0.688, 0.688, 0.688]
best validation: 0.72
best test: 0.741
num distinct structures: 2365
num distinct structures in training data: 136, number of distinct structures in test data: 925
num distinct structures exists in both training data and test data: 9
Experiment run 8
dataset: Cora
num_mp_layers: 3
num_fl_layers: 2
mp_hidden_dim: 3000
fl_hidden_dim: 4096
epsilon: 1.118033988749895
optimizer_lr: 0.01
loss_func: CrossEntropyLoss
total_epoch: 400
Epoch: 50, Loss: 0.0045, Train: 100.00%, Valid: 63.80%, Test: 63.80%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.20%, Test: 64.80%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 150, Loss: 0.0000, Train: 100.00%, Valid: 66.00%, Test: 64.40%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 200, Loss: 0.0000, Train: 100.00%, Valid: 66.20%, Test: 64.70%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 250, Loss: 0.0000, Train: 100.00%, Valid: 66.40%, Test: 64.70%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 300, Loss: 0.0000, Train: 100.00%, Valid: 66.20%, Test: 64.70%, Best Valid: 67.80%, Best Test: 66.10%
Epoch: 350, Loss: 0.0000, Train: 100.00%, Valid: 66.40%, Test: 64.80%, Best Valid: 67.80%, Best Test: 66.10%
train_accuracy_list: [0.14285714285714285, 0.14285714285714285, 0.15, 0.14285714285714285, 0.14285714285714285, 0.20714285714285716, 0.14285714285714285, 0.15, 0.20714285714285716, 0.2357142857142857, 0.32857142857142857, 0.22857142857142856, 0.17142857142857143, 0.19285714285714287, 0.30714285714285716, 0.25, 0.44285714285714284, 0.37142857142857144, 0.5857142857142857, 0.4857142857142857, 0.4714285714285714, 0.6428571428571429, 0.75, 0.5428571428571428, 0.6928571428571428, 0.7928571428571428, 0.7642857142857142, 0.8857142857142857, 0.8357142857142857, 0.9071428571428571, 0.9214285714285714, 0.9142857142857143, 0.9214285714285714, 0.9357142857142857, 0.9714285714285714, 0.9642857142857143, 0.9642857142857143, 0.9785714285714285, 0.9714285714285714, 0.9857142857142858, 0.9785714285714285, 0.9785714285714285, 0.9928571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
valid_accuracy_list: [0.122, 0.114, 0.164, 0.072, 0.072, 0.068, 0.058, 0.124, 0.174, 0.322, 0.26, 0.124, 0.062, 0.122, 0.14, 0.274, 0.284, 0.196, 0.412, 0.27, 0.218, 0.384, 0.444, 0.3, 0.44, 0.514, 0.462, 0.516, 0.588, 0.606, 0.602, 0.65, 0.678, 0.65, 0.632, 0.634, 0.63, 0.636, 0.626, 0.626, 0.632, 0.632, 0.628, 0.628, 0.628, 0.622, 0.626, 0.628, 0.638, 0.638, 0.648, 0.64, 0.624, 0.624, 0.634, 0.654, 0.662, 0.658, 0.634, 0.622, 0.622, 0.622, 0.622, 0.624, 0.628, 0.64, 0.652, 0.66, 0.658, 0.658, 0.658, 0.648, 0.638, 0.632, 0.632, 0.634, 0.642, 0.646, 0.648, 0.648, 0.652, 0.654, 0.654, 0.652, 0.648, 0.644, 0.642, 0.64, 0.642, 0.642, 0.642, 0.644, 0.64, 0.646, 0.646, 0.646, 0.648, 0.648, 0.652, 0.652, 0.652, 0.65, 0.652, 0.652, 0.652, 0.652, 0.65, 0.65, 0.652, 0.652, 0.654, 0.654, 0.656, 0.658, 0.66, 0.66, 0.658, 0.658, 0.658, 0.66, 0.66, 0.66, 0.66, 0.658, 0.656, 0.656, 0.656, 0.656, 0.656, 0.658, 0.658, 0.654, 0.656, 0.656, 0.656, 0.656, 0.658, 0.656, 0.656, 0.656, 0.656, 0.656, 0.658, 0.658, 0.658, 0.66, 0.658, 0.658, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.662, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.662, 0.662, 0.664, 0.664, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.662, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664, 0.664]
test_accuracy_list: [0.13, 0.103, 0.149, 0.091, 0.091, 0.1, 0.064, 0.13, 0.181, 0.319, 0.222, 0.142, 0.069, 0.136, 0.153, 0.271, 0.286, 0.2, 0.426, 0.282, 0.197, 0.37, 0.424, 0.302, 0.466, 0.535, 0.443, 0.529, 0.56, 0.618, 0.597, 0.661, 0.647, 0.651, 0.626, 0.631, 0.612, 0.618, 0.614, 0.622, 0.61, 0.614, 0.62, 0.623, 0.618, 0.62, 0.622, 0.623, 0.632, 0.638, 0.643, 0.647, 0.636, 0.63, 0.633, 0.646, 0.65, 0.649, 0.637, 0.631, 0.63, 0.632, 0.634, 0.635, 0.637, 0.638, 0.644, 0.658, 0.658, 0.656, 0.647, 0.639, 0.636, 0.634, 0.634, 0.634, 0.633, 0.635, 0.64, 0.645, 0.648, 0.649, 0.65, 0.65, 0.649, 0.645, 0.643, 0.642, 0.641, 0.644, 0.646, 0.645, 0.645, 0.64, 0.643, 0.642, 0.644, 0.649, 0.649, 0.648, 0.648, 0.648, 0.647, 0.645, 0.645, 0.646, 0.649, 0.647, 0.646, 0.646, 0.647, 0.647, 0.648, 0.649, 0.648, 0.649, 0.647, 0.647, 0.648, 0.647, 0.647, 0.647, 0.646, 0.646, 0.645, 0.644, 0.643, 0.642, 0.642, 0.644, 0.644, 0.644, 0.644, 0.644, 0.645, 0.644, 0.645, 0.645, 0.644, 0.644, 0.644, 0.644, 0.643, 0.643, 0.642, 0.642, 0.642, 0.642, 0.643, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.643, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.644, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.645, 0.647, 0.647, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.647, 0.647, 0.648, 0.647, 0.647, 0.647, 0.647, 0.647, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.649, 0.647, 0.647, 0.647, 0.648, 0.648, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.646, 0.647, 0.647, 0.647, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.648, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647, 0.647]
best validation: 0.678
best test: 0.661
End abalation study
